{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"03VKM-RVbZzY","colab_type":"code","colab":{}},"source":["# Using pytorch tutorial \n","# https://github.com/pytorch/examples/tree/master/mnist\n","# https://nextjournal.com/gkoehler/pytorch-mnist\n","\n","# TODO \n","# Inference by loading model and passsing into image\n","\n","# Import necessary packages\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import numpy as np\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","from time import time\n","\n","import os\n","from google.colab import drive "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcVdzRB1d2Ia","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n","        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n","        self.fc1 = nn.Linear(4*4*50, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = x.view(-1, 4*4*50)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","def train(log_interval, model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEs-TCrPd3gE","colab_type":"code","colab":{}},"source":["use_cuda = not False and torch.cuda.is_available()\n","\n","torch.manual_seed(1)\n","\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","batch_size=64\n","test_batch_size=1000\n","lr=0.01\n","momentum=0.5\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=test_batch_size, shuffle=True, **kwargs)\n","\n","\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_oMSFUPegXU","colab_type":"code","colab":{}},"source":["examples = enumerate(test_loader)\n","batch_idx, (example_data, example_targets) = next(examples)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rj-dy1nNe60Y","colab_type":"code","outputId":"ed3fc3bf-8f38-4d4a-8c96-76cf873b4042","executionInfo":{"status":"ok","timestamp":1569477740858,"user_tz":-600,"elapsed":1286,"user":{"displayName":"Damian Chiem","photoUrl":"","userId":"16249728721234339310"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["example_data.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1000, 1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"oYJcBRj7jnjB","colab_type":"code","colab":{}},"source":["fig = plt.figure()\n","for i in range(6):\n","  plt.subplot(2,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n","  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n","  plt.xticks([])\n","  plt.yticks([])\n","fig"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BquXIOINj86F","colab_type":"code","outputId":"31da86e4-866b-4e49-f3f4-d146e1d79798","executionInfo":{"status":"ok","timestamp":1569478785514,"user_tz":-600,"elapsed":181023,"user":{"displayName":"Damian Chiem","photoUrl":"","userId":"16249728721234339310"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epoch in range(1, 10 + 1):\n","    train(10, model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)\n","\n","\n","torch.save(model.state_dict(),\"mnist_cnn.pt\")\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311016\n","Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.236857\n","Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.153902\n","Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.108585\n","Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.746573\n","Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.453725\n","Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.003275\n","Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.850153\n","Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.826421\n","Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.471057\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.528206\n","Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.640848\n","Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.463647\n","Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.471361\n","Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.494021\n","Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.528746\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.396582\n","Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.368693\n","Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.265819\n","Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.331522\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.429057\n","Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.414001\n","Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.272681\n","Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.523167\n","Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.295353\n","Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.582970\n","Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.227801\n","Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.309506\n","Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.235378\n","Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.217832\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.354372\n","Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.227270\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.356548\n","Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.139246\n","Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.420800\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.279962\n","Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.278338\n","Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.190545\n","Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.229475\n","Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.237161\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.282160\n","Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.226082\n","Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.164687\n","Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.189844\n","Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.167540\n","Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.141826\n","Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.262153\n","Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.092365\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.249274\n","Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.081657\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.167490\n","Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.203824\n","Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.113926\n","Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.153293\n","Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.147649\n","Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.137372\n","Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.122267\n","Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.105159\n","Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.173493\n","Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.308299\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.296731\n","Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.175553\n","Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.145332\n","Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.109037\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.056970\n","Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.201683\n","Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.060500\n","Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.087710\n","Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.074391\n","Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.030735\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.206915\n","Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.055499\n","Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.072446\n","Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.128270\n","Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.111182\n","Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.100445\n","Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.210731\n","Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.139239\n","Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.221625\n","Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.056957\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.146195\n","Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.087830\n","Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.047579\n","Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.212997\n","Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.115647\n","Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.081075\n","Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.048085\n","Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.087296\n","Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.168338\n","Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.286647\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.039439\n","Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.050163\n","Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.105203\n","Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.225318\n","\n","Test set: Average loss: 0.1137, Accuracy: 9642/10000 (96%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.156497\n","Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.116420\n","Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.066215\n","Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.058282\n","Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.123179\n","Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.101646\n","Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.086997\n","Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.174431\n","Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.167947\n","Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.210019\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.075499\n","Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.112531\n","Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.031666\n","Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.156869\n","Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.109211\n","Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.109555\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.022064\n","Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.028727\n","Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.061198\n","Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.162794\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.088977\n","Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.056974\n","Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.062692\n","Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.050553\n","Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.157926\n","Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.101166\n","Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.378704\n","Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.067304\n","Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.083606\n","Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.023355\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.009027\n","Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.047543\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.070843\n","Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.146189\n","Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.110749\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.090948\n","Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.021063\n","Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.051222\n","Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.046941\n","Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.100744\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.124337\n","Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.063505\n","Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.033417\n","Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.050582\n","Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.087422\n","Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.028119\n","Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.273329\n","Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.175015\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.101048\n","Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.060724\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.245451\n","Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.060349\n","Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.101217\n","Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.087100\n","Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.065254\n","Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.045435\n","Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.101424\n","Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.066193\n","Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.036062\n","Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.144322\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.061622\n","Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.019430\n","Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.019795\n","Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.067661\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.092132\n","Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.065259\n","Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.119093\n","Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.034985\n","Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.041020\n","Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.149566\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.060707\n","Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.151998\n","Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.141322\n","Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.062510\n","Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.037581\n","Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.084302\n","Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.056510\n","Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.076036\n","Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.023460\n","Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.070282\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.052342\n","Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.050456\n","Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.060108\n","Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.132020\n","Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.025263\n","Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.131137\n","Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.011991\n","Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.058425\n","Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.162394\n","Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.016511\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.033401\n","Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.042101\n","Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.107625\n","Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.044673\n","\n","Test set: Average loss: 0.0706, Accuracy: 9779/10000 (98%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.085367\n","Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.116175\n","Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.048044\n","Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.023697\n","Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.150262\n","Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.154324\n","Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.018365\n","Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.038523\n","Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.075792\n","Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.046320\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.018439\n","Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.063586\n","Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.051726\n","Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.089669\n","Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.048633\n","Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.069230\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.042215\n","Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.102952\n","Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.050428\n","Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.103577\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.032729\n","Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.078088\n","Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.008614\n","Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.065701\n","Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.052293\n","Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.043034\n","Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.041373\n","Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.011493\n","Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.020858\n","Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.127056\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.062878\n","Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.047003\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.015118\n","Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.067844\n","Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.041072\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.114696\n","Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.027005\n","Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.028180\n","Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.023876\n","Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.111102\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.038611\n","Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.076971\n","Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.062054\n","Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.097362\n","Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.011237\n","Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.051869\n","Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.049315\n","Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.038691\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.037993\n","Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.089899\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.018115\n","Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.091823\n","Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.035340\n","Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.082721\n","Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.050331\n","Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.085804\n","Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.044801\n","Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.030832\n","Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.081276\n","Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.087117\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.075670\n","Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.034901\n","Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.129327\n","Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.033020\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.030399\n","Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.172115\n","Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.025729\n","Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.097070\n","Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.050157\n","Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.017800\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.022962\n","Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.025507\n","Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.135359\n","Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.100321\n","Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.065253\n","Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.130765\n","Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.039927\n","Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.045470\n","Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.037460\n","Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.068080\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.013213\n","Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.104061\n","Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.010686\n","Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.031567\n","Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.046360\n","Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.029912\n","Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.056022\n","Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.027882\n","Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.036204\n","Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.036649\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.026496\n","Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.054889\n","Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.095199\n","Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.061167\n","\n","Test set: Average loss: 0.0460, Accuracy: 9849/10000 (98%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.079184\n","Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.104711\n","Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.067832\n","Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.029340\n","Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.022093\n","Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.054609\n","Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.044106\n","Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.011063\n","Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.103054\n","Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.023374\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.085120\n","Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.076917\n","Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.029384\n","Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.125787\n","Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.030626\n","Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.058015\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.010032\n","Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.022249\n","Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.015421\n","Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.017352\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.091021\n","Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.070056\n","Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.008923\n","Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.054073\n","Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.032679\n","Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.007919\n","Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.017379\n","Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.076592\n","Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.021713\n","Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.152461\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.009230\n","Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.128879\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.058658\n","Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.104135\n","Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.147495\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.026546\n","Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.084742\n","Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.063471\n","Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.019844\n","Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.028929\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.063083\n","Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.024696\n","Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.018456\n","Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.056751\n","Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.003502\n","Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.120325\n","Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.027657\n","Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.078756\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.028370\n","Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.036957\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.004478\n","Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.088616\n","Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.010532\n","Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.029984\n","Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.023081\n","Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.073565\n","Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.037265\n","Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.047223\n","Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.012971\n","Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.034079\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.046440\n","Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.043194\n","Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.020789\n","Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.030640\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.045143\n","Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.073813\n","Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.008952\n","Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.103189\n","Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.196446\n","Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.011591\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.028174\n","Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.007302\n","Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.045224\n","Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.003969\n","Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.021500\n","Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.051748\n","Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.050355\n","Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.013585\n","Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.003941\n","Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.077988\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.021255\n","Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.011511\n","Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.054150\n","Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.085444\n","Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.026908\n","Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.083644\n","Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.051688\n","Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.209715\n","Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.055952\n","Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.082849\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.005919\n","Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.043256\n","Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.044818\n","Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.008577\n","\n","Test set: Average loss: 0.0512, Accuracy: 9826/10000 (98%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.025206\n","Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.014743\n","Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.091288\n","Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.031696\n","Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.020520\n","Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.044824\n","Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.051090\n","Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.041413\n","Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.022860\n","Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.020940\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.028050\n","Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.009544\n","Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.079191\n","Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.081683\n","Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.014909\n","Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.104751\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.010638\n","Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.006201\n","Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.007279\n","Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.024692\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.007793\n","Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.009006\n","Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.086848\n","Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.031473\n","Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.026672\n","Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.043563\n","Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.009582\n","Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.033434\n","Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.008318\n","Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.007479\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.058320\n","Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.030514\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.023736\n","Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.052590\n","Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.043292\n","Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.003840\n","Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.037401\n","Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.094315\n","Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.086601\n","Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.035125\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.003722\n","Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.025230\n","Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.055915\n","Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.016166\n","Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.045118\n","Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.041335\n","Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.019947\n","Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.040416\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.043113\n","Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.069409\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.050717\n","Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.008036\n","Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.119544\n","Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.063161\n","Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.051798\n","Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.078281\n","Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.031154\n","Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.081394\n","Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.146425\n","Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.033195\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.012897\n","Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.054373\n","Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.069138\n","Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.022341\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.102839\n","Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.135731\n","Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.020014\n","Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.010927\n","Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.012344\n","Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.104577\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.099252\n","Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.039500\n","Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.034389\n","Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.016343\n","Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.012728\n","Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.009132\n","Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.096665\n","Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.049841\n","Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.015535\n","Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.050764\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.017359\n","Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.020431\n","Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.028858\n","Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.050322\n","Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.050174\n","Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.008596\n","Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.067123\n","Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.023953\n","Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.076285\n","Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.006452\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.104358\n","Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.122711\n","Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.035314\n","Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.003169\n","\n","Test set: Average loss: 0.0359, Accuracy: 9875/10000 (99%)\n","\n","Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.038108\n","Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.111777\n","Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.037047\n","Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.002254\n","Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.040667\n","Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.008852\n","Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.021684\n","Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.002989\n","Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.041618\n","Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.004827\n","Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.022514\n","Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.102099\n","Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.074899\n","Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.048125\n","Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.086760\n","Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.016048\n","Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.023274\n","Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.011375\n","Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.024119\n","Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.015435\n","Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.034421\n","Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.034617\n","Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.034799\n","Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.033117\n","Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.095267\n","Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.007810\n","Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.014625\n","Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.044528\n","Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.006772\n","Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.060044\n","Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.006657\n","Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.041057\n","Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.081537\n","Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.048718\n","Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.024571\n","Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.147041\n","Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.027370\n","Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.028580\n","Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.027255\n","Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.007865\n","Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.057747\n","Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.023894\n","Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.016523\n","Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.040884\n","Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.012646\n","Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.008475\n","Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.015523\n","Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.019184\n","Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.006852\n","Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.039352\n","Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.027268\n","Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.035717\n","Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.056956\n","Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.045862\n","Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.047407\n","Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.081259\n","Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.080315\n","Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.006444\n","Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.028627\n","Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.004058\n","Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.103167\n","Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.004543\n","Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.088337\n","Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.004222\n","Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.010272\n","Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.069767\n","Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.036356\n","Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.011238\n","Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.009462\n","Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.022089\n","Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.033984\n","Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.057091\n","Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.025181\n","Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.036783\n","Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.004066\n","Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.008823\n","Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.043790\n","Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.001822\n","Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.046962\n","Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.006902\n","Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.060834\n","Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.076023\n","Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.133105\n","Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.042333\n","Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.015341\n","Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.010499\n","Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.003785\n","Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.013406\n","Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.036915\n","Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.009924\n","Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.012429\n","Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.002154\n","Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.001728\n","Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.036257\n","\n","Test set: Average loss: 0.0365, Accuracy: 9879/10000 (99%)\n","\n","Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.005724\n","Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.017103\n","Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.023095\n","Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.028302\n","Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.024629\n","Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.036089\n","Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.012783\n","Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.002011\n","Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.005519\n","Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.018236\n","Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.008636\n","Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.005895\n","Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.027937\n","Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.003023\n","Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.012907\n","Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.048472\n","Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.003767\n","Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.039113\n","Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.017332\n","Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.023666\n","Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.037729\n","Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.013537\n","Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.011377\n","Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.003453\n","Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.027131\n","Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.142669\n","Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.026605\n","Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.003905\n","Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.040878\n","Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.025795\n","Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.016278\n","Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.002822\n","Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.008475\n","Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.007230\n","Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.004544\n","Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.005338\n","Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.005317\n","Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.020763\n","Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.006171\n","Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.015037\n","Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.005498\n","Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.003590\n","Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.029528\n","Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.044751\n","Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.007869\n","Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.005771\n","Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.002085\n","Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.022638\n","Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.005125\n","Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.041029\n","Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.055128\n","Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.071999\n","Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.005272\n","Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.005981\n","Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.052371\n","Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.009824\n","Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.008916\n","Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.009606\n","Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.016802\n","Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.025591\n","Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.010814\n","Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.015497\n","Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.011633\n","Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.004006\n","Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.009630\n","Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.002000\n","Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.043164\n","Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.044865\n","Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.033392\n","Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.065387\n","Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.060639\n","Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.012701\n","Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.020825\n","Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.085017\n","Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.067019\n","Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.031217\n","Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.105184\n","Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.123592\n","Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.079319\n","Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.016714\n","Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.028462\n","Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.009000\n","Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.015518\n","Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.001786\n","Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.006051\n","Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.058468\n","Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.025919\n","Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.003787\n","Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.036309\n","Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.018770\n","Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.016868\n","Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.009649\n","Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.006938\n","Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.032937\n","\n","Test set: Average loss: 0.0310, Accuracy: 9895/10000 (99%)\n","\n","Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.014894\n","Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.012589\n","Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.009212\n","Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.051518\n","Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.079371\n","Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.032928\n","Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.055020\n","Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.003262\n","Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.004192\n","Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.006800\n","Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.094261\n","Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.013253\n","Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.003250\n","Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.042078\n","Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.020369\n","Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.022151\n","Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.015716\n","Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.000707\n","Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.032933\n","Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.049553\n","Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.018527\n","Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.083229\n","Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.109129\n","Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.002486\n","Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.027213\n","Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.047298\n","Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.047898\n","Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.008536\n","Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.011233\n","Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.003800\n","Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.020719\n","Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.012515\n","Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.015905\n","Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.055159\n","Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.007221\n","Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.080651\n","Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.053293\n","Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.027796\n","Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.042009\n","Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.011975\n","Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.007825\n","Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.015778\n","Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.006261\n","Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.006576\n","Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.036321\n","Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.054921\n","Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.018305\n","Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.006083\n","Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.071894\n","Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.013472\n","Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.006377\n","Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.003537\n","Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.011873\n","Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.012688\n","Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.037622\n","Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.013377\n","Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.006475\n","Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.001162\n","Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.013759\n","Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.009875\n","Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.017617\n","Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.081866\n","Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.020252\n","Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.005014\n","Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.015856\n","Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.038212\n","Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.025213\n","Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.005359\n","Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.004682\n","Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.020181\n","Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.006947\n","Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.003915\n","Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.016369\n","Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.004453\n","Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.093701\n","Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.091431\n","Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.007470\n","Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.011337\n","Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.024874\n","Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.001671\n","Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.011624\n","Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.005773\n","Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.019134\n","Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.003971\n","Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.018754\n","Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.004798\n","Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.030753\n","Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.054782\n","Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.141032\n","Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.005404\n","Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.058564\n","Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.001762\n","Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.034584\n","Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.044979\n","\n","Test set: Average loss: 0.0321, Accuracy: 9889/10000 (99%)\n","\n","Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.011876\n","Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.011992\n","Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.021894\n","Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.016990\n","Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.006555\n","Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.001776\n","Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.023579\n","Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.008019\n","Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.002657\n","Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.003652\n","Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.015378\n","Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.018344\n","Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.031350\n","Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.007412\n","Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.012323\n","Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.006156\n","Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.001271\n","Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.035505\n","Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.002525\n","Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.013933\n","Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.004778\n","Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.007980\n","Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.004770\n","Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.004143\n","Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.054176\n","Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.062738\n","Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.001583\n","Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.084179\n","Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.079816\n","Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.005406\n","Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.004396\n","Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.021388\n","Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.010214\n","Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.006071\n","Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.003519\n","Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.063152\n","Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.005371\n","Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.006983\n","Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.011848\n","Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.023191\n","Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.005180\n","Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.017849\n","Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.042917\n","Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.008714\n","Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.011921\n","Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.039144\n","Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.020406\n","Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.012013\n","Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.010624\n","Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.008586\n","Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.015552\n","Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.062032\n","Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.003131\n","Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.017826\n","Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.012234\n","Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.015985\n","Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.031438\n","Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.116698\n","Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.042689\n","Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.017885\n","Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.010290\n","Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.015892\n","Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.013645\n","Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.002468\n","Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.017981\n","Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.004715\n","Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.027430\n","Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.044870\n","Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.007845\n","Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.016674\n","Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.009268\n","Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.015366\n","Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.033414\n","Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.010848\n","Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.001316\n","Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.003952\n","Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.011701\n","Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.072420\n","Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.020212\n","Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.012707\n","Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000747\n","Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.000423\n","Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.003040\n","Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.003112\n","Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.045512\n","Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.006733\n","Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.011350\n","Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.005306\n","Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.008971\n","Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.024269\n","Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.016377\n","Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.063150\n","Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.005956\n","Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.009341\n","\n","Test set: Average loss: 0.0298, Accuracy: 9906/10000 (99%)\n","\n","Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.002729\n","Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.005510\n","Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.006178\n","Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.023102\n","Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.015174\n","Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.010213\n","Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.006798\n","Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.004871\n","Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.026740\n","Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.013942\n","Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.009010\n","Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.011995\n","Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.003871\n","Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.035749\n","Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.003774\n","Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.002238\n","Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.067123\n","Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.004110\n","Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.002274\n","Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.010192\n","Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.080456\n","Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.003608\n","Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.091163\n","Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.002404\n","Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.010968\n","Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.032916\n","Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.019086\n","Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.017282\n","Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.003019\n","Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.015170\n","Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.031610\n","Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.010196\n","Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.005659\n","Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.005115\n","Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.000867\n","Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.038179\n","Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.012660\n","Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.004508\n","Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.009158\n","Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.005916\n","Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.003442\n","Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.018890\n","Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.056461\n","Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.007364\n","Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.001846\n","Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.002324\n","Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.089669\n","Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.002557\n","Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.006053\n","Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.021977\n","Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.006488\n","Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.053689\n","Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.075672\n","Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.007147\n","Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.002726\n","Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.021809\n","Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.003777\n","Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.030244\n","Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.001691\n","Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.020120\n","Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.052656\n","Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.007584\n","Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.017916\n","Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.059928\n","Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.005690\n","Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.009417\n","Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.005850\n","Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.087099\n","Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.063176\n","Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.032193\n","Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.007169\n","Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.002096\n","Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.001396\n","Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.044095\n","Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.001679\n","Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.018185\n","Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.027126\n","Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.018685\n","Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.048586\n","Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.063106\n","Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006659\n","Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.002089\n","Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.001817\n","Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.020325\n","Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.015212\n","Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.001989\n","Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.002863\n","Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.010582\n","Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.033817\n","Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.009645\n","Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.010611\n","Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.051854\n","Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.041246\n","Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.021602\n","\n","Test set: Average loss: 0.0260, Accuracy: 9909/10000 (99%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ecGgWgORNJU8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"662d6e5f-797d-4ed5-82de-ddd4faf37f4a","executionInfo":{"status":"ok","timestamp":1569479242201,"user_tz":-600,"elapsed":1255,"user":{"displayName":"Damian Chiem","photoUrl":"","userId":"16249728721234339310"}}},"source":["model.state_dict()"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('conv1.weight',\n","              tensor([[[[ 8.4955e-02, -1.2888e-01, -1.4602e-01, -5.6271e-02, -2.8044e-01],\n","                        [ 1.6911e-01,  5.3543e-02,  1.3692e-01,  2.9686e-02, -3.8869e-02],\n","                        [ 1.0998e-01,  1.5787e-01,  2.4384e-01,  7.3657e-02,  5.6897e-02],\n","                        [-6.6997e-02,  5.3629e-02,  7.1094e-02,  2.6750e-01,  1.7109e-01],\n","                        [-1.7501e-01, -2.0437e-01, -1.3883e-01, -1.4623e-01, -6.0436e-03]]],\n","              \n","              \n","                      [[[ 6.7087e-02,  2.9218e-01,  2.1498e-01, -2.5886e-01,  1.4298e-02],\n","                        [ 1.3635e-01,  3.7389e-01,  1.8357e-01, -2.9947e-01, -3.2644e-01],\n","                        [ 3.7456e-02,  3.8923e-01, -1.4999e-02, -4.8464e-02, -2.3349e-01],\n","                        [ 3.1294e-01,  6.1769e-02,  1.5774e-01, -7.5200e-02, -1.6371e-01],\n","                        [ 2.0687e-01,  5.1365e-03,  7.6493e-02, -6.5340e-02, -1.9717e-02]]],\n","              \n","              \n","                      [[[-2.5322e-01, -1.3731e-01,  9.6422e-02,  4.8298e-02,  3.4508e-01],\n","                        [ 1.0223e-01,  1.6613e-02,  6.1898e-03,  3.3623e-01,  2.0481e-01],\n","                        [-1.1881e-01,  2.1957e-01,  2.9816e-01,  3.2930e-01, -9.5429e-02],\n","                        [ 4.4368e-02,  1.1305e-01,  1.1438e-01, -1.4357e-01, -2.0936e-01],\n","                        [ 2.0979e-01,  2.3463e-02,  8.9721e-02, -5.3583e-02, -9.0530e-04]]],\n","              \n","              \n","                      [[[ 4.0023e-02,  6.2563e-02,  8.7168e-02, -1.7415e-01,  1.5973e-01],\n","                        [-1.5308e-01, -1.7534e-01, -8.7864e-04, -9.8238e-03,  1.9236e-01],\n","                        [-1.2776e-01, -1.8684e-01,  1.5686e-01,  1.2429e-02,  1.6795e-01],\n","                        [ 5.1862e-02, -1.3564e-01,  9.2640e-02,  8.6178e-02, -1.1060e-01],\n","                        [-8.7185e-02,  9.8725e-02,  9.0016e-02, -5.5982e-02, -4.5136e-02]]],\n","              \n","              \n","                      [[[ 2.6535e-01,  7.6036e-02,  2.2113e-01,  1.0671e-01, -1.8593e-01],\n","                        [-8.0499e-02,  3.9723e-01,  2.0431e-01,  1.5358e-01, -4.8160e-02],\n","                        [ 1.7165e-01,  4.4968e-01,  4.0424e-01, -1.3453e-01, -6.2611e-02],\n","                        [ 2.2533e-01,  3.7770e-01,  3.0754e-01, -1.2102e-01, -1.9560e-01],\n","                        [-8.3051e-02,  1.5468e-01,  3.4985e-01, -6.4054e-02,  1.1553e-01]]],\n","              \n","              \n","                      [[[-1.7049e-01, -2.7352e-01, -7.7189e-02,  2.2794e-01,  3.2400e-01],\n","                        [-1.2453e-01,  1.2294e-01,  3.6282e-01,  3.6242e-01,  2.3542e-01],\n","                        [ 2.5987e-01,  2.8682e-01,  2.2445e-01, -7.2044e-04, -1.2637e-01],\n","                        [ 7.4462e-03,  3.4835e-02, -9.8063e-02,  1.1133e-01,  7.1946e-02],\n","                        [-2.1497e-02,  5.1007e-02,  2.8729e-02,  1.2110e-01,  1.3148e-01]]],\n","              \n","              \n","                      [[[-8.8003e-02,  1.5464e-01, -6.4671e-02, -3.4779e-02, -1.9700e-01],\n","                        [-1.5209e-01, -1.6551e-01, -1.4451e-01,  8.9770e-02, -8.1339e-02],\n","                        [-1.6863e-01,  4.2320e-02,  1.3266e-02,  8.1481e-02, -1.1826e-01],\n","                        [ 4.9777e-02, -7.9542e-02, -6.6243e-02, -1.8190e-01, -8.5950e-02],\n","                        [-1.3671e-02,  1.2943e-01,  8.6701e-02,  1.1569e-01,  2.8889e-01]]],\n","              \n","              \n","                      [[[ 2.8168e-01,  2.2258e-01,  1.7404e-02, -1.6346e-01,  1.4325e-01],\n","                        [ 5.0149e-02,  1.3416e-02, -2.2369e-01, -9.1427e-02, -1.4711e-01],\n","                        [ 2.4571e-01, -1.9440e-01, -2.2418e-01, -4.5954e-02, -9.5678e-02],\n","                        [ 1.0684e-01, -7.5309e-02, -1.0541e-01,  3.4903e-02,  1.9504e-01],\n","                        [-9.6956e-02,  1.6168e-01,  2.1127e-01,  2.6446e-01, -1.1564e-01]]],\n","              \n","              \n","                      [[[ 4.4886e-02, -1.8557e-01,  1.5915e-01, -6.8396e-02,  9.8115e-02],\n","                        [ 9.2398e-03, -3.4673e-02,  6.6483e-02,  2.0562e-01,  2.3415e-01],\n","                        [ 8.6268e-02,  1.0364e-01, -9.4468e-02,  2.9426e-01,  3.7087e-01],\n","                        [ 1.9771e-01,  1.4984e-01, -1.8912e-01, -1.1579e-01,  2.7098e-01],\n","                        [-2.4753e-01,  6.5390e-02, -2.8842e-01, -2.5404e-01,  1.0893e-01]]],\n","              \n","              \n","                      [[[-1.1849e-01,  6.2526e-03,  2.5865e-01,  2.6767e-01,  2.5881e-01],\n","                        [-4.1306e-02, -1.6169e-01,  2.7236e-01,  5.5996e-02, -1.3171e-02],\n","                        [ 3.9664e-03, -2.0878e-01,  1.2333e-01,  1.9210e-01, -9.6009e-02],\n","                        [-2.4501e-01, -1.2306e-01,  3.4995e-02,  3.1280e-02, -4.6647e-02],\n","                        [-6.9082e-02, -2.7617e-01, -1.8721e-01, -1.1215e-01,  2.1847e-01]]],\n","              \n","              \n","                      [[[ 2.4539e-01, -1.2216e-02,  4.7335e-02,  1.2228e-01,  2.9630e-02],\n","                        [-3.3173e-03,  2.6932e-01,  2.8085e-01,  8.2035e-02, -1.0361e-02],\n","                        [ 2.6962e-01,  3.4410e-01,  3.8257e-02,  3.0920e-01,  7.6005e-02],\n","                        [-1.3360e-01,  1.7232e-01, -8.8309e-02,  2.3774e-01, -1.3895e-01],\n","                        [ 1.8872e-02,  8.0133e-02,  8.2411e-02,  2.0442e-01, -9.0789e-02]]],\n","              \n","              \n","                      [[[-6.7112e-02, -1.3852e-01,  3.3454e-02, -7.8615e-02,  1.8725e-04],\n","                        [-2.7948e-02,  1.0191e-01,  2.4036e-01,  9.7797e-02, -6.9807e-02],\n","                        [-1.0441e-01, -1.5795e-01,  2.3786e-01,  2.6251e-02,  7.7447e-02],\n","                        [ 9.1108e-04, -1.2047e-01,  1.7699e-01,  1.8020e-01,  5.4100e-02],\n","                        [-1.1822e-01, -6.0990e-02,  5.9289e-02, -8.1480e-02, -1.0788e-01]]],\n","              \n","              \n","                      [[[-3.6182e-02, -7.5313e-02,  4.2896e-02,  5.1933e-02,  1.3903e-01],\n","                        [-1.1804e-01, -2.4085e-01,  9.9469e-02,  9.7636e-02,  3.3891e-01],\n","                        [-1.0873e-01, -1.2859e-01, -2.4034e-01,  2.6457e-02,  3.1619e-01],\n","                        [-2.8076e-01, -1.6085e-01,  6.9315e-02,  1.9118e-01,  2.1795e-01],\n","                        [-1.2079e-01, -7.0042e-02, -1.5965e-02,  3.5257e-02,  2.0548e-01]]],\n","              \n","              \n","                      [[[-7.1765e-02, -1.1462e-01,  4.7623e-02, -1.4133e-01, -5.1274e-02],\n","                        [ 9.2622e-02,  6.6957e-02,  1.6401e-01, -1.4185e-01, -6.3266e-03],\n","                        [-8.7644e-02, -1.3418e-01, -1.3805e-01,  1.2182e-02, -9.4231e-03],\n","                        [-1.3024e-01, -1.6783e-01, -1.9729e-01,  1.4221e-01, -7.8218e-02],\n","                        [-7.9739e-02, -1.0408e-01, -1.3780e-01, -2.2900e-01, -1.6390e-01]]],\n","              \n","              \n","                      [[[ 3.2333e-01,  3.1123e-01,  1.8576e-01,  7.2775e-02,  1.9436e-01],\n","                        [ 3.4870e-01,  5.0328e-01,  3.8171e-01,  3.0401e-01,  1.1445e-01],\n","                        [-2.2003e-01, -2.0232e-01,  1.4277e-01, -2.7159e-03,  1.4184e-01],\n","                        [-2.1926e-01, -3.8213e-01, -3.0036e-01, -7.8590e-02, -5.3485e-02],\n","                        [-3.6746e-01, -9.7007e-02, -1.5101e-01, -1.7350e-01,  4.7358e-02]]],\n","              \n","              \n","                      [[[ 3.9197e-02, -1.0578e-01,  1.6371e-01,  5.2030e-02, -7.8114e-02],\n","                        [ 2.9196e-03, -1.4822e-01,  1.6572e-01, -1.3079e-01, -2.7457e-01],\n","                        [ 2.4863e-01,  2.2322e-01,  1.6252e-01, -3.1831e-02, -1.2744e-01],\n","                        [ 1.4351e-01,  3.7114e-01,  2.6975e-01,  1.0098e-01,  2.9512e-01],\n","                        [-4.3157e-03,  2.3444e-01,  2.1321e-01,  3.6868e-01,  2.6538e-01]]],\n","              \n","              \n","                      [[[-1.3408e-01,  9.1068e-02, -3.6664e-02, -1.7539e-01, -5.1838e-02],\n","                        [-2.1670e-01, -1.5566e-01, -1.8317e-01,  1.2886e-01, -3.3082e-02],\n","                        [-3.5186e-02,  8.6221e-02,  7.3146e-02, -1.0051e-01,  1.1404e-01],\n","                        [ 1.2028e-01, -1.1849e-01,  2.2223e-01, -5.3477e-02, -2.9318e-02],\n","                        [-1.3319e-01,  2.4530e-01,  1.1307e-01,  2.5256e-01,  7.2511e-02]]],\n","              \n","              \n","                      [[[ 1.3725e-01, -7.7907e-02, -2.0690e-01, -3.7341e-03, -1.1647e-02],\n","                        [-2.9614e-02, -1.1844e-01,  1.4150e-02,  1.2636e-01,  1.5545e-01],\n","                        [-1.6099e-01,  1.5752e-01,  1.4624e-01,  2.7631e-01,  2.4283e-01],\n","                        [-9.1700e-02,  2.9615e-01, -9.8648e-02,  1.6730e-01,  2.1125e-02],\n","                        [ 1.8371e-01, -6.0767e-02,  1.1775e-01, -1.6041e-01, -2.3884e-01]]],\n","              \n","              \n","                      [[[ 1.2466e-01,  2.2890e-01,  3.6440e-01,  1.0239e-01,  2.5364e-01],\n","                        [ 1.2808e-01, -5.4987e-02, -6.3689e-02,  1.8651e-01, -7.2022e-02],\n","                        [ 1.9900e-02, -1.9725e-01,  1.2311e-01,  6.8076e-02, -9.3459e-03],\n","                        [ 7.3844e-03, -2.0008e-01, -9.7595e-02,  2.2802e-02, -6.5805e-02],\n","                        [-1.0591e-01, -1.1698e-01,  1.7851e-01,  2.2846e-01,  2.5816e-01]]],\n","              \n","              \n","                      [[[ 1.3127e-01, -2.0240e-01,  4.6956e-02,  6.7051e-02, -1.7520e-01],\n","                        [ 2.3224e-02, -1.5199e-01,  3.5166e-02,  1.6418e-01,  2.4416e-01],\n","                        [-1.5064e-01, -1.5200e-01,  2.7815e-01,  2.0354e-01,  1.6947e-01],\n","                        [ 7.0722e-02,  8.2852e-03,  1.8317e-01, -1.9810e-01,  9.5150e-03],\n","                        [ 1.2272e-01,  1.7780e-01, -1.4173e-01, -2.1970e-01,  2.9356e-02]]]],\n","                     device='cuda:0')),\n","             ('conv1.bias',\n","              tensor([-0.1440, -0.1371, -0.1571, -0.0778,  0.0497, -0.0720, -0.0488, -0.1326,\n","                       0.1877,  0.0131, -0.0573,  0.0608, -0.1334,  0.1951,  0.2046, -0.1136,\n","                      -0.1132, -0.0801, -0.0989,  0.0547], device='cuda:0')),\n","             ('conv2.weight',\n","              tensor([[[[-4.2785e-02, -2.8654e-02,  1.7675e-02, -6.9919e-03, -4.1069e-03],\n","                        [-3.9947e-02,  3.6780e-02,  1.9571e-02, -4.6321e-03, -1.4678e-02],\n","                        [ 3.0633e-03,  2.6680e-02,  4.1355e-02,  3.0744e-02, -4.7510e-03],\n","                        [-1.6560e-02,  3.6041e-02,  8.8152e-03, -1.6834e-02,  3.9872e-02],\n","                        [ 4.4490e-02, -2.5051e-02, -2.3723e-02, -1.4091e-02, -3.0726e-02]],\n","              \n","                       [[ 1.4711e-02, -2.8592e-02,  4.4047e-02, -4.4514e-02,  2.6313e-02],\n","                        [-1.4245e-02, -1.3346e-02,  5.2875e-02, -5.1627e-02, -1.9797e-02],\n","                        [-9.0673e-03,  2.4469e-02,  4.7591e-03, -2.0328e-02, -1.0092e-02],\n","                        [-3.2695e-02, -2.9477e-02, -7.0865e-03, -2.7062e-02,  2.9071e-02],\n","                        [-1.1517e-02, -4.5168e-02, -3.2178e-02,  5.7414e-03,  3.2448e-03]],\n","              \n","                       [[ 1.7732e-02, -1.3405e-02, -4.2086e-02, -4.3549e-02, -2.4423e-02],\n","                        [-2.0753e-02, -6.0465e-03, -2.8828e-02,  7.8725e-03, -1.8529e-02],\n","                        [ 2.2905e-02,  2.5738e-03, -2.4273e-02,  3.4776e-02,  1.1162e-03],\n","                        [-3.7248e-02, -3.0566e-02,  1.3794e-02,  2.7354e-02,  5.0479e-02],\n","                        [-2.2225e-02,  1.8870e-02,  3.5892e-02,  2.8710e-02, -7.7187e-03]],\n","              \n","                       ...,\n","              \n","                       [[-9.9249e-03, -3.7806e-02, -8.6950e-03, -1.9909e-02,  1.3065e-02],\n","                        [ 3.7118e-02, -2.4979e-02, -9.7769e-03,  4.9494e-02, -3.8308e-02],\n","                        [-1.3113e-02,  4.4804e-02,  2.4292e-02,  1.3687e-02, -2.3001e-02],\n","                        [-1.4370e-02, -4.8364e-02, -4.5489e-02, -2.5256e-02,  5.6209e-02],\n","                        [ 2.6580e-02,  1.7804e-02,  1.0977e-03,  4.9918e-02, -1.6768e-02]],\n","              \n","                       [[ 3.9938e-02,  1.7702e-02, -2.0827e-02,  6.2735e-03,  5.7678e-03],\n","                        [-3.6304e-02,  3.5777e-02, -1.8438e-02,  2.2007e-02,  3.6644e-02],\n","                        [-9.3986e-03,  4.1663e-02,  2.7267e-02,  4.7330e-02, -1.7785e-02],\n","                        [-1.4624e-02, -4.4125e-03,  6.3081e-02, -3.2775e-02, -3.7369e-02],\n","                        [ 1.1592e-02,  4.4745e-02,  3.1223e-02, -3.8438e-02, -3.4889e-02]],\n","              \n","                       [[ 4.2965e-02,  7.5616e-04, -3.7153e-02, -2.3714e-03,  2.6855e-02],\n","                        [-1.1825e-04, -2.1530e-02, -2.6763e-02, -1.7425e-03,  6.6870e-03],\n","                        [ 2.4173e-02,  4.7271e-02, -8.7487e-03,  3.9829e-03, -2.4671e-02],\n","                        [ 2.8611e-02,  5.6991e-02,  5.1335e-02,  4.3892e-02,  1.2629e-02],\n","                        [-5.5189e-03,  1.5894e-02, -1.9796e-02,  1.3938e-02, -3.7152e-02]]],\n","              \n","              \n","                      [[[-5.4562e-02, -1.2582e-02, -1.1193e-02, -2.1090e-02,  1.2321e-02],\n","                        [-4.2837e-03, -3.7595e-03, -3.5422e-02, -4.6841e-02,  3.3593e-03],\n","                        [-6.3187e-03, -1.5124e-03,  3.2961e-02,  9.8204e-04,  1.6654e-02],\n","                        [-3.7869e-03, -1.6848e-02,  2.4387e-02, -2.9701e-02,  8.3440e-04],\n","                        [-3.6357e-02,  4.3973e-02, -1.7616e-02,  4.9856e-02,  3.8851e-02]],\n","              \n","                       [[ 2.7989e-02,  3.3530e-02, -2.1604e-03, -1.9021e-02, -3.4984e-03],\n","                        [-5.8333e-03, -6.3700e-03,  1.4124e-02, -3.0601e-02,  1.4005e-02],\n","                        [ 2.3335e-02,  6.1636e-02, -3.9919e-02, -6.0048e-02,  1.4714e-02],\n","                        [ 2.6534e-02,  6.2583e-02, -3.5447e-02,  4.1525e-03, -5.4526e-02],\n","                        [-4.4184e-03,  2.3216e-03, -2.2710e-02, -3.0588e-02,  3.5158e-03]],\n","              \n","                       [[ 4.1410e-02,  6.2364e-02, -2.1012e-02, -3.8257e-03, -3.2037e-02],\n","                        [-2.9001e-02, -1.9755e-02,  2.3898e-02, -1.6717e-02, -1.4760e-03],\n","                        [ 3.3633e-02, -1.9510e-02,  1.5551e-02,  2.0255e-02,  3.4651e-02],\n","                        [ 8.1952e-03, -5.2606e-02, -5.8577e-02, -3.1764e-02,  3.9596e-02],\n","                        [ 2.4438e-02,  8.6570e-03, -4.1999e-02, -3.2276e-02,  3.4458e-02]],\n","              \n","                       ...,\n","              \n","                       [[ 2.6188e-02, -1.0241e-02,  1.9944e-02, -2.3455e-02, -1.2131e-02],\n","                        [-1.0618e-02,  2.8863e-03,  1.0045e-02, -8.2522e-03, -1.5460e-02],\n","                        [-6.5329e-03,  3.3585e-03, -4.8161e-02, -2.2404e-02, -4.4160e-02],\n","                        [ 1.0989e-03, -1.2805e-02,  2.1010e-02,  3.0228e-02, -3.7287e-02],\n","                        [-2.5766e-02, -6.7923e-03,  4.6618e-03, -9.5598e-03, -3.1829e-02]],\n","              \n","                       [[-1.7920e-02, -2.4474e-02,  3.0490e-02, -4.3803e-03,  2.8414e-02],\n","                        [-2.0424e-02, -1.1050e-02, -3.2651e-02, -4.0191e-02,  7.4708e-03],\n","                        [-7.5732e-03,  2.1951e-02,  2.2763e-02, -5.2121e-02, -2.7522e-03],\n","                        [ 5.4223e-03, -1.4600e-02, -3.0029e-02, -2.0771e-02,  1.8035e-02],\n","                        [ 1.4342e-02,  3.5635e-02,  3.4113e-03,  2.4274e-02,  1.2834e-02]],\n","              \n","                       [[-1.7904e-02,  6.1620e-03, -3.7740e-02, -5.3034e-03, -1.4969e-02],\n","                        [-2.1432e-02, -3.5481e-02, -1.6605e-02, -3.6275e-02, -5.1252e-03],\n","                        [ 3.9229e-03, -3.1361e-02,  2.9252e-02,  2.0514e-02,  8.4807e-03],\n","                        [-4.3885e-03,  7.3056e-03, -3.2051e-02,  2.6817e-02,  4.4481e-02],\n","                        [-4.4882e-03,  4.2825e-02,  5.0340e-02,  1.7181e-04, -1.8422e-02]]],\n","              \n","              \n","                      [[[ 3.7043e-03,  3.8864e-04, -5.5412e-02, -2.5712e-02, -2.7620e-02],\n","                        [ 3.5177e-02, -1.9740e-02,  3.6350e-03,  1.3926e-02, -2.9782e-02],\n","                        [ 8.2724e-03, -2.4751e-02, -4.7820e-02, -3.8662e-02, -2.6778e-03],\n","                        [ 2.6708e-03, -2.2898e-02,  4.0912e-03,  4.0895e-02,  2.4995e-02],\n","                        [ 7.8191e-03, -4.5784e-03, -4.3148e-02, -1.1610e-02, -1.2804e-02]],\n","              \n","                       [[ 1.0073e-02, -6.1816e-02, -3.9172e-02,  7.8362e-02,  8.0499e-02],\n","                        [-5.6505e-02,  1.4733e-03, -2.1979e-03,  1.0417e-01,  3.2020e-02],\n","                        [-1.8695e-02, -3.0926e-04,  5.9731e-02,  1.1821e-01, -1.0190e-02],\n","                        [-4.1654e-02,  1.1208e-02,  5.4834e-02,  6.9787e-02, -4.9499e-02],\n","                        [ 6.5821e-03,  1.7636e-02,  2.1116e-03,  3.1070e-02, -1.2214e-02]],\n","              \n","                       [[-6.1678e-02, -5.0214e-02, -6.3489e-03, -6.9104e-03,  1.9510e-02],\n","                        [ 4.0530e-02, -2.1778e-02,  1.5674e-02,  7.4446e-02,  3.0887e-03],\n","                        [ 1.7473e-02, -1.0156e-02,  2.7022e-02, -4.4925e-02, -2.3644e-02],\n","                        [ 4.2555e-02, -8.8067e-03, -4.5621e-02,  4.5892e-03,  3.3922e-02],\n","                        [ 3.7513e-02, -1.2324e-02, -2.0238e-02,  2.0051e-03, -2.9022e-02]],\n","              \n","                       ...,\n","              \n","                       [[-1.1572e-02, -1.9662e-02, -4.8214e-02,  4.5883e-02, -1.6209e-02],\n","                        [-4.5360e-02, -2.4231e-02, -3.2002e-02, -2.0437e-03, -5.4673e-02],\n","                        [-1.7187e-02, -2.3598e-02,  3.0761e-02,  5.6550e-03,  4.1058e-02],\n","                        [ 5.0476e-03,  2.8472e-02, -5.3712e-02, -4.0388e-02,  3.1099e-02],\n","                        [-3.0419e-04, -1.0780e-02,  6.8179e-03,  3.0996e-02,  3.0180e-02]],\n","              \n","                       [[-3.5005e-02, -2.7691e-02,  2.1689e-02,  1.5661e-02, -3.0907e-02],\n","                        [-2.1106e-02,  3.0160e-02,  5.9118e-02, -8.9498e-03, -2.5285e-02],\n","                        [-4.3338e-02,  1.1570e-02,  4.5182e-02, -3.3921e-02, -5.6010e-02],\n","                        [-5.2418e-02,  3.1543e-02,  5.4964e-02,  5.1547e-02,  3.0244e-02],\n","                        [-2.2238e-02,  6.1781e-03,  1.9070e-02, -1.5200e-02, -3.4070e-02]],\n","              \n","                       [[ 3.3244e-02, -1.5279e-02, -4.8511e-03, -1.1749e-02, -6.3050e-03],\n","                        [-2.0852e-02, -1.9228e-02,  3.0727e-02,  2.5784e-02, -2.8497e-02],\n","                        [ 3.1518e-02, -4.3565e-02,  9.3179e-03, -3.8999e-02,  3.1730e-03],\n","                        [ 3.0144e-02, -4.6700e-02,  1.0274e-02, -5.0998e-02, -2.7519e-03],\n","                        [-3.3793e-02, -1.7403e-02, -3.9743e-02,  1.5228e-02, -3.7271e-02]]],\n","              \n","              \n","                      ...,\n","              \n","              \n","                      [[[ 2.2502e-02,  3.4778e-02, -3.9375e-02, -2.9807e-02,  3.2480e-02],\n","                        [ 3.7576e-03,  2.0602e-02, -5.5075e-02, -3.3120e-02,  6.9163e-03],\n","                        [ 2.1744e-02, -5.3811e-02, -1.2629e-02, -3.9769e-02, -2.9010e-02],\n","                        [-3.5002e-02, -5.3719e-02, -5.0946e-02, -3.9838e-03,  7.8312e-03],\n","                        [ 1.3799e-02,  1.1504e-02,  8.7291e-04,  2.9127e-02,  1.2408e-02]],\n","              \n","                       [[ 2.2073e-02,  4.8718e-02, -3.5938e-02, -2.5080e-02, -2.6352e-02],\n","                        [ 1.7807e-02,  3.9627e-03, -4.1393e-02, -3.1194e-03,  1.8470e-02],\n","                        [ 5.1001e-02, -1.0155e-03,  6.8249e-03,  6.6887e-03,  7.5975e-02],\n","                        [ 3.0730e-02, -7.4880e-04, -2.7229e-02,  9.8614e-03,  3.0186e-02],\n","                        [ 6.3835e-03,  7.1370e-03,  9.9005e-03,  9.0964e-03,  2.1073e-02]],\n","              \n","                       [[ 3.5927e-02, -2.9845e-02, -4.4431e-02,  4.8608e-03, -2.8813e-02],\n","                        [-9.5601e-03,  2.5615e-03,  6.8857e-03, -1.6517e-02,  6.5325e-02],\n","                        [-1.0656e-02,  6.3171e-03, -6.3921e-03,  7.8837e-03,  9.8995e-03],\n","                        [-5.9615e-02, -3.9450e-03,  1.8072e-02,  6.1895e-02,  2.2735e-02],\n","                        [ 3.1983e-02,  3.6967e-02,  1.8349e-02,  1.4556e-02,  3.5116e-02]],\n","              \n","                       ...,\n","              \n","                       [[-7.0148e-03,  1.0231e-02,  1.5833e-02,  1.2769e-02,  2.5174e-02],\n","                        [ 2.8334e-02, -5.7300e-02, -8.6289e-05,  2.3571e-02, -5.5727e-03],\n","                        [ 3.3946e-02, -5.7104e-02,  4.7363e-02,  1.0978e-02, -2.9600e-02],\n","                        [-1.3177e-02,  7.6676e-04,  5.5861e-02, -2.9695e-02,  3.2594e-02],\n","                        [-4.9505e-02,  7.9223e-03,  3.9418e-02, -7.7880e-03,  2.9755e-02]],\n","              \n","                       [[-3.0658e-02, -1.7654e-02,  9.9808e-03,  1.3325e-02,  2.0481e-02],\n","                        [-4.7215e-02, -1.8876e-02, -5.2270e-03,  3.1553e-04, -6.0591e-03],\n","                        [-1.3500e-02,  5.2589e-03, -1.4135e-03, -1.3365e-02,  1.5088e-02],\n","                        [ 2.4880e-02, -4.4709e-02, -2.3522e-02,  2.2631e-02, -2.0231e-02],\n","                        [-4.8001e-02,  1.3101e-02, -4.4240e-02,  1.4863e-02,  1.3867e-03]],\n","              \n","                       [[ 4.4163e-02, -1.7686e-02, -3.2983e-02,  2.6595e-02,  2.5369e-02],\n","                        [ 4.3771e-02, -1.9914e-02,  1.5127e-02,  4.1657e-02,  5.8738e-02],\n","                        [-3.8070e-02,  1.2950e-02, -3.7969e-02,  8.2615e-03,  1.0913e-02],\n","                        [ 1.3557e-03,  2.3041e-02, -2.7346e-02,  4.6067e-02, -5.0826e-03],\n","                        [ 2.4272e-02,  1.2421e-03,  3.4454e-02, -4.5379e-02,  4.4643e-02]]],\n","              \n","              \n","                      [[[ 1.2660e-02, -2.4067e-02,  3.9944e-02,  2.4354e-02, -7.8555e-03],\n","                        [-4.0246e-02,  9.9124e-03,  2.3518e-02, -4.2283e-02,  5.1554e-03],\n","                        [ 4.5340e-02,  2.4244e-02,  1.3629e-02,  3.9446e-02, -1.5316e-02],\n","                        [-1.2970e-02,  1.9704e-02, -3.0865e-02,  1.5562e-02,  4.1727e-03],\n","                        [-2.2814e-02,  2.1367e-02,  2.5004e-02, -4.6519e-02,  3.4077e-02]],\n","              \n","                       [[ 1.2279e-02,  8.7050e-03,  8.1314e-04,  3.8778e-02,  1.9363e-02],\n","                        [-8.6676e-03,  2.2120e-02,  2.5541e-02, -3.3805e-02, -4.4010e-02],\n","                        [ 2.4521e-02,  6.3035e-03,  2.1029e-02, -1.9095e-02,  3.8507e-02],\n","                        [ 2.1004e-02,  3.5469e-02,  4.6224e-03, -3.2242e-02,  2.2946e-02],\n","                        [-1.6409e-02,  5.3565e-02, -3.4899e-02,  2.4606e-02, -9.4977e-03]],\n","              \n","                       [[-5.7090e-03, -1.1220e-02,  4.0740e-02,  6.5214e-02,  4.4447e-03],\n","                        [-2.7959e-02, -3.8012e-02,  2.7560e-02, -6.6976e-03, -3.4192e-02],\n","                        [-3.6071e-02, -2.5915e-02, -3.2270e-02,  3.8078e-02, -2.4319e-02],\n","                        [ 8.2188e-03, -1.3473e-02, -4.9559e-02,  1.6535e-02, -2.1581e-03],\n","                        [ 2.7151e-02,  3.7368e-03, -3.4294e-02, -2.9488e-02,  4.5297e-02]],\n","              \n","                       ...,\n","              \n","                       [[-2.7373e-02, -2.4005e-02,  3.0088e-02,  8.0254e-03, -3.5967e-02],\n","                        [ 1.1406e-02,  2.6075e-02,  6.5604e-03,  1.1808e-02, -2.9903e-02],\n","                        [-2.3196e-02, -3.4816e-02, -1.0022e-02, -3.8617e-02,  4.6133e-02],\n","                        [-6.2442e-03, -4.0310e-02,  3.1661e-02, -1.9803e-02, -4.0558e-02],\n","                        [-2.9248e-02, -3.0119e-02, -3.0703e-02,  2.3575e-02, -4.4342e-02]],\n","              \n","                       [[-1.3152e-02,  2.9803e-03, -4.6355e-03,  6.2061e-02,  6.6500e-02],\n","                        [ 4.5491e-03, -1.5659e-02,  5.5078e-02, -4.0353e-02, -1.6014e-02],\n","                        [ 1.8810e-02,  3.4032e-02, -4.0580e-02, -1.7767e-02,  1.3832e-02],\n","                        [-3.8328e-02,  3.0109e-02,  2.1916e-02,  2.5770e-02, -1.2672e-02],\n","                        [-2.5989e-02,  3.2484e-02, -1.1527e-02,  6.1887e-03,  1.8789e-02]],\n","              \n","                       [[-2.2072e-02,  6.4225e-04, -2.6676e-02, -1.7422e-03, -1.2471e-02],\n","                        [-4.6196e-02,  2.0167e-02, -4.5534e-02, -3.5982e-02, -1.8452e-03],\n","                        [-1.7980e-02, -3.7636e-02, -4.4645e-02,  3.5970e-02, -5.4247e-03],\n","                        [-3.7653e-02,  4.6849e-03, -3.6944e-02,  5.5231e-03, -7.8713e-03],\n","                        [ 7.6288e-03,  3.6905e-02,  2.6270e-02,  1.5346e-02, -3.0697e-02]]],\n","              \n","              \n","                      [[[ 1.1910e-02, -2.6466e-02,  3.6394e-02,  4.1388e-02, -3.1444e-02],\n","                        [ 3.1152e-02,  4.5163e-02, -2.2481e-02,  1.0464e-02,  1.9332e-03],\n","                        [-3.4383e-02,  6.0465e-03,  8.8627e-03, -2.0080e-02,  5.3414e-05],\n","                        [ 2.0291e-02,  5.5697e-02, -1.4471e-02,  2.1581e-02,  4.2810e-02],\n","                        [ 2.9195e-02,  1.5131e-02,  4.2063e-02, -2.5902e-02,  1.4833e-02]],\n","              \n","                       [[-1.0311e-02, -8.7437e-03, -1.6881e-02,  1.3687e-02, -2.1240e-02],\n","                        [-2.9898e-02,  3.9205e-02, -3.2663e-02, -3.6815e-02, -2.9122e-02],\n","                        [ 1.7254e-02,  3.0128e-02,  8.6860e-03, -3.7646e-02, -2.4270e-02],\n","                        [ 4.6109e-02, -3.7067e-02, -2.4955e-02, -3.2687e-02,  3.2177e-02],\n","                        [-3.1670e-02, -2.5816e-02, -6.6128e-02, -3.1728e-02,  5.8972e-03]],\n","              \n","                       [[-3.1754e-02,  9.4021e-03,  8.5730e-02,  4.0500e-02, -3.2893e-02],\n","                        [ 3.2379e-02,  5.8552e-02,  2.1855e-02, -3.3365e-02,  4.3883e-02],\n","                        [ 9.8245e-03, -6.0283e-02, -5.1934e-02, -4.7180e-03, -2.3763e-02],\n","                        [-2.7058e-03,  1.2679e-02, -5.8008e-02, -5.2068e-02, -6.4966e-02],\n","                        [-5.2866e-02, -4.3508e-02, -4.5037e-02,  7.0203e-03, -6.4563e-03]],\n","              \n","                       ...,\n","              \n","                       [[-1.0510e-02,  6.8142e-03,  2.6412e-02,  5.6454e-02,  6.6720e-03],\n","                        [ 4.2879e-02, -6.5230e-03, -6.9885e-03,  7.7930e-04,  3.6192e-02],\n","                        [-4.3372e-02, -2.2230e-03,  1.8442e-02, -1.7254e-02,  2.4082e-03],\n","                        [-5.3038e-02, -1.6276e-03, -5.4728e-03, -3.6400e-02, -1.5025e-03],\n","                        [ 3.1117e-02, -9.9446e-03,  2.3955e-02,  4.0000e-02, -1.3305e-03]],\n","              \n","                       [[ 2.0565e-02,  2.5429e-02, -4.5698e-02, -2.7651e-02, -3.1942e-02],\n","                        [-5.1643e-03, -5.0312e-03,  5.3607e-02,  1.8996e-02, -2.5493e-02],\n","                        [ 2.7471e-02,  4.7780e-02, -1.3256e-02, -2.7328e-02, -1.4885e-02],\n","                        [ 2.7440e-02,  2.2440e-02, -6.1819e-03,  2.7923e-02, -1.6372e-02],\n","                        [ 3.0707e-02,  1.8144e-02,  2.3323e-02, -1.9234e-02,  2.2188e-02]],\n","              \n","                       [[ 2.6382e-02,  6.6575e-02,  7.4915e-02, -6.1406e-06,  3.5817e-02],\n","                        [-1.1682e-02,  6.0531e-02, -1.5959e-02, -5.2764e-03, -1.7058e-02],\n","                        [ 1.2196e-02,  3.3939e-02,  4.2605e-02,  2.3252e-05, -2.9567e-03],\n","                        [-3.5467e-02,  1.1754e-02,  2.8811e-02, -2.4971e-02,  2.1619e-04],\n","                        [ 4.6350e-02,  2.2857e-02,  1.3941e-02,  1.3718e-02,  4.3201e-02]]]],\n","                     device='cuda:0')),\n","             ('conv2.bias',\n","              tensor([-0.0249, -0.0230,  0.0391,  0.0100, -0.0359, -0.0328,  0.0224, -0.0181,\n","                       0.0135,  0.0328, -0.0366, -0.0402, -0.0183, -0.0012,  0.0039, -0.0144,\n","                       0.0299, -0.0270, -0.0266, -0.0012,  0.0246,  0.0205,  0.0008,  0.0106,\n","                      -0.0237, -0.0078, -0.0107,  0.0450,  0.0319, -0.0071,  0.0112, -0.0253,\n","                       0.0055, -0.0358, -0.0177,  0.0385,  0.0033, -0.0139, -0.0245, -0.0038,\n","                       0.0181,  0.0416,  0.0213,  0.0191, -0.0277,  0.0445,  0.0014, -0.0184,\n","                       0.0005, -0.0423], device='cuda:0')),\n","             ('fc1.weight',\n","              tensor([[ 0.0285, -0.0316, -0.0171,  ...,  0.0195, -0.0318,  0.0086],\n","                      [-0.0199, -0.0060, -0.0121,  ...,  0.0138, -0.0220,  0.0013],\n","                      [ 0.0115, -0.0035, -0.0143,  ...,  0.0186,  0.0189,  0.0189],\n","                      ...,\n","                      [-0.0140,  0.0121,  0.0104,  ...,  0.0106, -0.0210,  0.0253],\n","                      [-0.0011,  0.0247, -0.0061,  ..., -0.0211,  0.0150,  0.0293],\n","                      [-0.0111,  0.0310, -0.0198,  ..., -0.0108,  0.0363, -0.0359]],\n","                     device='cuda:0')),\n","             ('fc1.bias',\n","              tensor([-0.0201,  0.0004,  0.0325,  0.0121,  0.0207,  0.0069,  0.0331,  0.0126,\n","                       0.0226,  0.0134,  0.0235, -0.0266, -0.0169,  0.0049, -0.0261, -0.0077,\n","                      -0.0044, -0.0097,  0.0273,  0.0089,  0.0331,  0.0060, -0.0229,  0.0297,\n","                       0.0083, -0.0254,  0.0139,  0.0339,  0.0322,  0.0234, -0.0020, -0.0263,\n","                      -0.0162,  0.0062, -0.0121,  0.0083, -0.0187,  0.0053,  0.0176, -0.0086,\n","                       0.0302, -0.0216,  0.0192,  0.0337,  0.0059,  0.0090, -0.0226,  0.0267,\n","                       0.0143, -0.0227,  0.0234,  0.0283, -0.0304,  0.0138, -0.0104,  0.0134,\n","                      -0.0147, -0.0294, -0.0294,  0.0317, -0.0056, -0.0132,  0.0195, -0.0146,\n","                      -0.0130,  0.0105, -0.0116, -0.0144,  0.0156, -0.0177, -0.0025,  0.0256,\n","                       0.0150, -0.0318, -0.0033,  0.0363,  0.0243, -0.0205, -0.0346,  0.0343,\n","                      -0.0052, -0.0166,  0.0211, -0.0331, -0.0257, -0.0084, -0.0087,  0.0355,\n","                       0.0296, -0.0350, -0.0119,  0.0112, -0.0316,  0.0203,  0.0244, -0.0258,\n","                       0.0013, -0.0168,  0.0119,  0.0105,  0.0257, -0.0124, -0.0105,  0.0208,\n","                      -0.0126, -0.0033, -0.0108,  0.0066, -0.0295, -0.0226,  0.0358,  0.0225,\n","                      -0.0033,  0.0175,  0.0311,  0.0324, -0.0016,  0.0184,  0.0255,  0.0221,\n","                       0.0196,  0.0041,  0.0330, -0.0082,  0.0194,  0.0232, -0.0019,  0.0009,\n","                      -0.0071, -0.0312,  0.0173, -0.0323, -0.0177,  0.0260,  0.0245, -0.0025,\n","                      -0.0141, -0.0071, -0.0201, -0.0206, -0.0232, -0.0074, -0.0278, -0.0294,\n","                      -0.0180,  0.0340,  0.0363, -0.0153,  0.0368, -0.0240, -0.0056, -0.0170,\n","                      -0.0319, -0.0280,  0.0316,  0.0044,  0.0020,  0.0056, -0.0235, -0.0035,\n","                      -0.0344, -0.0201, -0.0323, -0.0129,  0.0285, -0.0014,  0.0253,  0.0219,\n","                      -0.0009,  0.0141, -0.0116, -0.0145,  0.0319,  0.0305,  0.0302,  0.0318,\n","                       0.0333,  0.0104, -0.0119, -0.0039, -0.0148,  0.0279, -0.0209,  0.0047,\n","                      -0.0311,  0.0006,  0.0110,  0.0246, -0.0185, -0.0168, -0.0172, -0.0231,\n","                       0.0129, -0.0100, -0.0158, -0.0263, -0.0219, -0.0279,  0.0266,  0.0228,\n","                       0.0282, -0.0010,  0.0318, -0.0258,  0.0329, -0.0267, -0.0105,  0.0142,\n","                      -0.0204,  0.0169, -0.0120, -0.0300,  0.0268, -0.0267, -0.0059, -0.0187,\n","                       0.0343, -0.0039,  0.0049, -0.0232,  0.0100, -0.0324,  0.0351,  0.0186,\n","                       0.0062,  0.0163, -0.0109,  0.0324, -0.0116, -0.0170, -0.0364, -0.0240,\n","                       0.0306,  0.0146,  0.0101, -0.0324,  0.0112,  0.0239,  0.0229, -0.0244,\n","                      -0.0331,  0.0080,  0.0177,  0.0180,  0.0283, -0.0222, -0.0344,  0.0300,\n","                       0.0201, -0.0098,  0.0231,  0.0321, -0.0129,  0.0003, -0.0263, -0.0264,\n","                      -0.0162, -0.0278, -0.0039, -0.0165, -0.0174,  0.0215, -0.0226,  0.0260,\n","                      -0.0288, -0.0033,  0.0059,  0.0053, -0.0228, -0.0150, -0.0236, -0.0140,\n","                       0.0291,  0.0191,  0.0148,  0.0094,  0.0007, -0.0341, -0.0129,  0.0327,\n","                       0.0118, -0.0074,  0.0322, -0.0275,  0.0155, -0.0256, -0.0242, -0.0195,\n","                       0.0025,  0.0219,  0.0006,  0.0243,  0.0323,  0.0184,  0.0026, -0.0220,\n","                       0.0237, -0.0234, -0.0124, -0.0018,  0.0061,  0.0119,  0.0064,  0.0038,\n","                       0.0235,  0.0316,  0.0331,  0.0018,  0.0364, -0.0077,  0.0140, -0.0318,\n","                      -0.0220, -0.0254,  0.0293, -0.0290,  0.0319, -0.0050,  0.0049, -0.0055,\n","                      -0.0217, -0.0169,  0.0193, -0.0074,  0.0221,  0.0255, -0.0319, -0.0237,\n","                      -0.0316, -0.0099,  0.0074,  0.0272, -0.0094, -0.0172, -0.0112,  0.0306,\n","                       0.0001,  0.0134, -0.0291, -0.0346, -0.0288,  0.0267, -0.0155, -0.0034,\n","                      -0.0031, -0.0054,  0.0302, -0.0091, -0.0272, -0.0288, -0.0265,  0.0084,\n","                       0.0162,  0.0300, -0.0100,  0.0138, -0.0294,  0.0157, -0.0056, -0.0003,\n","                       0.0341, -0.0240, -0.0269, -0.0083,  0.0055,  0.0366,  0.0132, -0.0202,\n","                      -0.0284, -0.0202,  0.0119, -0.0072, -0.0038,  0.0242, -0.0011,  0.0127,\n","                       0.0140,  0.0189,  0.0105, -0.0264, -0.0175,  0.0181, -0.0309, -0.0341,\n","                      -0.0202, -0.0166, -0.0031, -0.0233,  0.0089, -0.0126,  0.0375, -0.0157,\n","                       0.0113, -0.0229,  0.0375, -0.0129, -0.0052, -0.0336,  0.0157,  0.0133,\n","                       0.0324,  0.0353, -0.0359,  0.0178, -0.0082,  0.0085, -0.0264,  0.0092,\n","                       0.0038, -0.0266, -0.0178,  0.0294,  0.0272, -0.0275, -0.0319,  0.0092,\n","                       0.0139,  0.0145, -0.0284, -0.0003, -0.0353, -0.0078, -0.0146, -0.0241,\n","                       0.0254,  0.0274, -0.0200,  0.0139,  0.0061, -0.0211, -0.0187, -0.0315,\n","                       0.0190, -0.0086, -0.0265, -0.0130, -0.0113, -0.0013, -0.0292,  0.0177,\n","                       0.0156, -0.0104,  0.0339,  0.0128,  0.0305, -0.0069,  0.0355,  0.0037,\n","                      -0.0201,  0.0147,  0.0188,  0.0253, -0.0124,  0.0090,  0.0014, -0.0292,\n","                      -0.0199, -0.0148,  0.0075, -0.0241, -0.0177,  0.0135, -0.0127,  0.0343,\n","                       0.0105,  0.0211,  0.0164, -0.0162,  0.0091, -0.0098, -0.0034, -0.0314,\n","                       0.0006, -0.0294,  0.0208, -0.0099,  0.0378,  0.0134,  0.0153,  0.0314,\n","                      -0.0247,  0.0197, -0.0264,  0.0187,  0.0176, -0.0263,  0.0173, -0.0330,\n","                      -0.0209, -0.0272, -0.0042, -0.0136,  0.0029, -0.0205,  0.0352, -0.0030,\n","                      -0.0172, -0.0185, -0.0068, -0.0256], device='cuda:0')),\n","             ('fc2.weight',\n","              tensor([[ 0.0355,  0.0054,  0.0501,  ..., -0.0663, -0.0170, -0.0241],\n","                      [ 0.0559,  0.0193, -0.0228,  ...,  0.0558, -0.0136,  0.0482],\n","                      [-0.0625,  0.0422,  0.0326,  ...,  0.0864, -0.1042, -0.0554],\n","                      ...,\n","                      [ 0.0442,  0.0661,  0.0008,  ...,  0.0326, -0.0081,  0.0660],\n","                      [-0.0303, -0.0227, -0.0189,  ...,  0.0258,  0.0310, -0.0251],\n","                      [-0.0321,  0.0390,  0.0135,  ..., -0.0392, -0.0094, -0.0306]],\n","                     device='cuda:0')),\n","             ('fc2.bias',\n","              tensor([ 0.0178,  0.0251, -0.0062, -0.0174,  0.0142,  0.0113,  0.0063,  0.0421,\n","                       0.0286,  0.0091], device='cuda:0'))])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"u8zd3JgNrh_f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"965ce579-8ddf-485b-dc62-740a35bb71e5","executionInfo":{"status":"ok","timestamp":1569479479098,"user_tz":-600,"elapsed":1217,"user":{"displayName":"Damian Chiem","photoUrl":"","userId":"16249728721234339310"}}},"source":["# Print model's state_dict\n","print(\"Model's state_dict:\")\n","for param_tensor in model.state_dict():\n","    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Model's state_dict:\n","conv1.weight \t torch.Size([20, 1, 5, 5])\n","conv1.bias \t torch.Size([20])\n","conv2.weight \t torch.Size([50, 20, 5, 5])\n","conv2.bias \t torch.Size([50])\n","fc1.weight \t torch.Size([500, 800])\n","fc1.bias \t torch.Size([500])\n","fc2.weight \t torch.Size([10, 500])\n","fc2.bias \t torch.Size([10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ih9gHQnwL06d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ffba3861-b706-42bc-a38a-4d534ce9de6a","executionInfo":{"status":"ok","timestamp":1569479961600,"user_tz":-600,"elapsed":1149,"user":{"displayName":"Damian Chiem","photoUrl":"","userId":"16249728721234339310"}}},"source":["loaded_model = Net().to(device)\n","loaded_model.load_state_dict(torch.load(\"mnist_cnn.pt\", map_location=device))"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IncompatibleKeys(missing_keys=[], unexpected_keys=[])"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"eHmhQJ3nL5wb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"134662eb-3e93-4c65-9a0a-a7b80901a4b6","executionInfo":{"status":"ok","timestamp":1569479975629,"user_tz":-600,"elapsed":3141,"user":{"displayName":"Damian Chiem","photoUrl":"","userId":"16249728721234339310"}}},"source":["# loaded_model.eval()\n","\n","\n","test(loaded_model, device, test_loader)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["\n","Test set: Average loss: 0.0260, Accuracy: 9909/10000 (99%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QsGExYmmTkhw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHb8ZTowRY-Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}