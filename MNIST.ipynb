{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "03VKM-RVbZzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using pytorch tutorial \n",
        "# https://github.com/pytorch/examples/tree/master/mnist\n",
        "# https://nextjournal.com/gkoehler/pytorch-mnist\n",
        "\n",
        "# TODO \n",
        "# Inference by loading model and passsing into image\n",
        "\n",
        "# Import necessary packages\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "from google.colab import drive "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcVdzRB1d2Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEs-TCrPd3gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = not False and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "batch_size=64\n",
        "test_batch_size=1000\n",
        "lr=0.01\n",
        "momentum=0.5\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=test_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_oMSFUPegXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj-dy1nNe60Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a4c12ee-9c6a-491b-c718-e97442fe7c52"
      },
      "source": [
        "example_data.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYJcBRj7jnjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "2c10fe0a-1ae4-4b74-8be2-473533d2f287"
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzAAAAISCAYAAAATGyqSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYZFWZJ+DvsFPsFAKiQCkg2Aoi\n7dICyqIt2oK4IEsriigyY9O4YoOK0i2C3UWjLDoqMoOogyiCoij6OCjIwAiIYCubCAUizS5rUaDU\nmT/uza40yXMzKzIyIk/l+z5PPlGRv7jnnlziq/zi3jg35ZwDAACgBssNewIAAACTpYEBAACqoYEB\nAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACq\noYEBAACqoYGpTErpqJRSTimdNuy5DFpKaff2a//1sOcCs5UapAbBMKlBalDEkBqYlNIqKaWDUkrf\nSindnFJ6OKX0WErpjpTSBSmlT6SUthnG3JY1KaXT2l/2Xj7mDXCee7dFaftB7bMXKaXnpZROTynd\n2v7O3pVSOj+l9Lphz43JU4MGRw3qr5TS8imlQ1JKl6WUHkgpPZhSuiKl9N6U0grDnh+TowYNjhrU\nXymlF6eUvppSWtD+zi5MKd2QUvpiSuk5g5rHwItdSmmPiPhiRGw46tOLIuKRiHhKROzSfnw0pfSj\niHhzzvmeQc9zGfJARNw5zudXjYg123+Pl0dEPDEtMxrf3hHxxoh4OCIuGeB+Jy2ldFBEfC6WPG/+\nGBHrRMRuEbFbSukLOef/Nqz5MTlq0MCpQX2SUlolIr4fze9nRPN7GxHx1+3HG1JKu+WcHx3G/Jgc\nNWjg1KA+SSkdFhH/GhGp/dTCiFg+IrZoPw5IKR2Yc/7qdM9loEdgUkrviIhvR/OkvT4iDoyIjXLO\nq+ac142IlaIpwkdGxO0R8cqIePog57isyTm/J+e84diPiHjPqMc8KW8/fj/Eqc8oKaWXRsTno2le\nvhkRG7e/s2tGxHsj4s8RcXBK6R+HN0smogYNnhrUV/8ezR+2D0fEvhGxWkTMiYi9IuLBiHhpRHxm\naLNjQmrQ4KlB/ZFSekEsaV6+FxFb5pxXi6YR3C4iLo2IFSPilJTS06Z7PgNrYFJK20Xz6vVyEfGd\niNg25/y/cs7/OfKYnPMTOecrc85HR8QzIuLoiPjToOYIHT4Wze/utRGxX875toiInPOjOecTIuLT\n7eOOSimtPqQ50kENomYppWdExLvau+/JOZ+Zc16cG9+KiHe32TtSSpsPZ5Z0UYOo3H7RNC93RcSb\ncs43RES0NeiXEbFHRDweEatExKunezKDPAJzdDSvLNwSEW/JOS/qenDO+fGc85E559+M/nxKaef2\nvMQF7f1Xp5R+0L4XYXFK6b1jHr9BSunfU0rXtefpPdCeO/yBlNLK4+07pfTTdh8HlObXnvuXU0o7\nj/n8X7y5LKX0tpTSz1NKD7XnKv8kpfS3XV97SmnLlNIZ7df0aDv3j5fmO93a86tzSmmvlNJ6KaXj\nU0q/bed2W/uY1UedM7peYZzntvnDoz63e0opR3PYNCJi/pjzTx8eb6x2211T8/6T+9qf7S/a07z6\nKqU0JyJ2au+enHMe75Dy8e3tuhHxmn7Pgb5Qg9SgKmtQa+9ojgDfGRGnj5OfERG3RXM6x77TNAem\nRg1Sg2quQRu0t9eO97ubc743Iha0d1ebpjn8l4E0MCmljWNJN3ZCzrn4w1jKcT8QzfnAu0Vz2Grx\nmPxFEXFNRLw/IraM5jSflSLihRFxXET8PKW0fj/mUpjflyLitGgOBy+OiDUiYueIOD+l9MbCNi+L\niCuj+Q/oKdF0s8+IiKMi4ift/IflaRHxy4h4XzSHtP/chzEXRfMf8mPt/Yfa+6M/niSl9O6I+HE0\nh9eXiyWHML+YUjq6sM1xExWDgqdG8/sV0Rzyf5Kc8x3RnGcbEdFZmBk8NUgN6lBDDYpY8r6XC3LO\nT/q6c86L2/lEROzaw/hMIzVIDepQSw1a0N4+OzXvxxs79tyImNfevbKH8ZfKoI7A7DTq3+f1acwN\nojkX73MR8dSc8zoRsXpEnBURkVJaJ5rzTNeNiP+IiBflnNdsH/OmaN6A/byI+Fqf5jPWnhHx5oj4\n7xGxZs55rYh4ZkRcFM33/aQ0ZsWYds7fjOac5iujOby8Vjvnt7XzfXcMz9HRPMFeHhFzcs4jhahn\nOecft+eifq/91L+MOf90s3E22yQiToim+K6fc147IuZGxKltfnhqTrfolzzq38t3PG4kG9gqHEya\nGqQGjauSGhQR8Vft7W86HnPNmMcyc6hBatC4KqpBp0VzOuP6EfHNlNKzIiJS4/kRcW40zeU5Oeef\n9XnfTzKoBubZ7e2iiPhtn8ZcJSK+kXP+h5zznREROedFI+9NiIhDonnl/P6IeGXO+fL2MU/knM+K\nJYfYX5FSmo5Xq9aOiHfmnD+fc17Y7vvmaM4hfLyd29il8g6J5hfj3ojYLed8dbvdn3LOp0fEwRGx\n1jTMdbJWaOd1Qc45t3O7cQjzWCOaU7k+lNuVWXLO90VzfvjvomkkXt/H/f1nLDkHedw/DFJKm0RT\nYCOany0zixoUalAfDboGRSxZser2jseMZOunlFznbWZRg0IN6qOB16D269w7miNEu0fE9SmlRyLi\n0WiazXkR8fH2MdNuUAVu3fb2/pEf+FgppY+kZv3zsR8ndIw7vyPbq739Unt6z1/IOf8omhUTIqbn\nm31rRPzvcfZ7e0Rc1t597ph4ZM6n5PGXTPxaNOfODsvZOeffDXH/I3JEfOpJn2xOofhue3fs9zZy\nzh/MOaec81K9yT43S5KOvJpwaOEc3H8a9e81lmZ8BkINWrJfNWjqBlqDUkorxZLTWLuWSF44skkM\n4Bx0looatGS/atDUDbQGjdr+29GcCjmyOtuciBj5m2iVaC4t8aTTy6bDTHqFZo1oDoeO/Sh12o9G\nxNXjBW2xH/nB/aRjnxe0t9st7WQn4YpSkYqIP7S364x8op3zyKlHF463UTveRX2b4dK7dOKHDMTv\nR15tGseTvrd9cnQ0BeMZEfG9lNJ2KaUVU0pPSyl9MppD5CNHaRaXBmFGU4PUoMkaRg1i2acGqUGT\nNfAalFJaLqU0PyIujoj7onnf1dxofkdfH81Rs/dGxM/SAFZjHVQDc197u3ZKKY33gJzz4W1XmHLO\nKSY+J/PettMcz7qx5Gv7Q+ExEc2KLRHNm8T67aGObGT1hhVHfW7dWPIeiq5TBLq+nul29xD3PdrS\nfm+nLOf8k2jWjF8cEa+IiF9Ecwj8toj4cDRFbeSVpvv7uW/6Qg36S2rQ1Ay0BuWcH48lL5Cs2vHQ\nOSObRHNRRGYONegvqUFTM/C/gyLioIj4YDRHX16ac/5Rzvm+nPNd7ZGZnaL5+2fbaBY5mFaDamCu\nbW9XieZKnf0w2aujDuRQ1iwxyCvSzjg555OiWUnlSxHx62gOj18azeouO8eS98D06/xm+kcNWjbM\n5ho0cq2QjToeM5Ld1fGHLcOhBi0bZnMNGrnw56k55yc1ULm5ntGZ7d09p3syg2pgRh8KHMQ1Mu6L\nJafxbNLxuJGr247tqEeWxet60vf7TWT3xZInxmT+g5ppRi8lWPq+DfONd32Rc74q53xQznnrnPOm\nOeftc86fzjn/KZYcgp8ph5hZQg2amBo0s42sMNa1yuHIIiPXdDyG4VCDJqYGzVDtanEjjffNHQ+9\nqb2dN60TigE1MDnn30fED9q775nuc+Paw+2/bu/u0vHQkVU3xq5XPXIK0NNjHKm5yvHaPU9wHO2c\nR5bHfFlhv6mUDVtuLmo0sob5uN+3aNadLxkptOMeWp/pUkovjub9MTmaC8oxg6hBE1ODZnwNGnkf\nwy5jl56NaM5Pj2Zp14iI/zOwWTEpatDE1KAZXYOeiCXz6mqIN21vu05x64tBvon/o9G8Z2DTiPjq\neBfB6bOz2tsDUkpPWtY2pfTKiHhJe/cbY+L/aG9fWxj78KlPb1zfbG8PSimtO06+bwygq52Cke/b\nkw4dppRWi4h/7Nj2wfa2rwVxEFJKq0bEie3ds4a0pCITU4MmpgbN3Br0zWhe4d0wIt4yTr5PRGwc\nzR8aZ46TM3xq0MTUoBlYg9rFE37V3t2/cCHLdSJi5OKkP5/uOQ2sgck5XxnNxYcWR/ODvSqldODo\nJ1V7MZzNUkqHRbO6wVScHM05w6tGc8XXF7T7WL69+uvX28f9OOd8wZhtz4rmlfStU0onpJTWbrdd\nP6V0YkTsH0uWq+ynz0bEXRGxXkT8MKW0TbvfFVNKb4mIU2LJ1d5nopECeGhK6e/bFUUipbRtRPww\nulfEGHnVZfeU0nS8mXBKV6BNKa2SUvp0SuklKaU57eeWTyntEs2pAS+K5k2HXcWJIVKDJkUNmqE1\nqL1+xhfbuyemlPZuVwVKKaXXR8T/aLNTvYgyM6lBk6IGzdAaFEtqzLMi4ryU0jZtDVqhPQvlh9Gs\nSJYj4qQ+Tbks5zzQj4jYI5onVB718Wg0518uGvP570fElmO237nNFkxiXy+K5pzKkfEebPc1cv/q\naK5gOt62x4+Zyx+jKTp/jogDImJB+/mdx2x3VPv50zrmdVr7mKPGyXaKpiiM7Pf+Ud+XSyLi2InG\nn+TP4YCRfUzisVe0j91rgset2n5PR+b+ePs9zxFxZzTru+eIeHicbZ826rF/jqYZWBARvxn1mN3b\n/Ncdczikfcz3xsmOK+1/Et+D1cf5ffjTqPs3RMQWg34++Vj6DzVIDaqxBrXbrxLNqWSjf29H/6wu\niohVh/0c8zHhz1ENUoOqq0HRnEJ2yji/t4+Nuv9ERLx3EM+jgV8HJuf83Yh4ZjRXCz0nmgsSLY6I\nNaN5clwYEcdExHNyzn+Xc75+Cvu6LJo3NX46mj8wV4zml+KKiDgsIl6cc76rsPkHonml5OpY8sT5\nYUTsmnM+rdc5TWLOF0bE86M5BeDuaC4QtCCagrBrLDm/csbJzQUfd46Iz0SzQldE82Q8JZo3uF/X\nse0fovn6zo2m2K4fzWH2TadvxktlUTTLJf84miUc50TzKtDF0azMsXXO2epjFVCDJpyzGjQza1Dk\n5hz7V0TEodH8Dv0pmj8Yroxm2dJd2+8BM5gaNOGc1aAZWINy46BoLmT5rWiWU14umt+LmyLiy9H8\nPn1mEPNJbVcFAAAw4w38CAwAAECvNDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1\nNDAAAEA1NDAAAEA1NDAAAEA1VujHICmlmyNizYhY0I/xYBk2LyIezDk/Y9gTWZaoQTBp80IN6js1\nCCZtXvShBqWc85RnklK6NyLWnfJAMEvknNOw57AsUYNg6ahB/aUGwdKZag3q1ylkC/o0DkAvFgx7\nAsCstmDYE4DZxHtgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACA\namhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhg\nAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAaqww7AkA\nMHyrr756MTv99NM7t91zzz172ucll1zSmZ966qk9jdvl4osv7sxvvPHGvu8TgP5yBAYAAKiGBgYA\nAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGZZQBZomupZJPPPHEYrbHHnt0jrt48eJids899xSz\nm266qXPcrrxr6ea99967mN1///2d++ya73vf+95idvXVV3eOC3TbbLPNitkRRxzRue1aa61VzLbe\neutiNtGy6r/+9a+L2fnnn1/Mrrvuus5xmTpHYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpo\nYAAAgGpoYAAAgGqknPPUB0npFxGx3dSnw3h23333znyLLbYoZscff3wx67p2w3TZddddO/MLL7xw\nQDMZrpxzGvYcliVq0OScffbZxWyia710WbBgQTHba6+9itl0XTtl3rx5xeyss87q3Pb5z39+MfvM\nZz5TzD7wgQ9MOK+ZRA3qLzVo6o488shidtRRR3Vu+8QTTxSzP/7xj8VsjTXW6Bx35ZVXLmYPP/xw\nMTv99NOL2UTXtOkad1ky1RrkCAwAAFANDQwAAFANDQwAAFANDQwAAFANDQwAAFANDQwAAFANyyj3\n2bOe9axitv/++xezt771rcVs3XXX7dznqquuWsxSKq9S14+f/dJ65JFHOvN99tmnmJ1//vn9ns7Q\nWMK0v9SgJbbaaqti9pvf/KaYdS2r3rVMckTEnnvuWcyuueaazm0Hbe7cuZ35RRddVMw222yzYva5\nz32uc9wPf/jDxWzRokWd204HNai/1KCp66oVW265Zee2n/3sZ4vZoYceWsy23XbbznFf85rXFLOu\nS1y86EUvKma33npr5z533nnnYnbLLbd0blsTyygDAACzhgYGAACohgYGAACohgYGAACohgYGAACo\nhgYGAACohmWUl9K8efM68wsuuKCYbbLJJn2ezcQuvfTSge+z63u00UYbdW77jW98o5jtt99+vU5p\nxrGEaX/Npho0f/78zvy1r31tMdt8882L2V133VXMXvWqV3Xu8+qrr+7Ma3LAAQcUs1NOOaXncbu+\n98NYGlUN6q/ZVIOm4iMf+Ugx+/jHP17Mll9++c5xDz/88GI2Uc3s1UorrVTMPvrRjxazru9BRMRN\nN91UzLbffvtidvfdd3eOO9NYRhkAAJg1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAA\nAEA1Vhj2BGai973vfcXsXe96V+e2m266aTF75JFHitmVV15ZzE4++eTOfXY566yzet62V8cdd1wx\n6/reRkTMmTOnmK288srF7LHHHpt4YlCJo446qpi9//3v73nc5ZYrv2b1ox/9qJgtS9d5mciNN95Y\nzLqus7DBBht0jrvjjjsWs2FcBwaGYf/99y9mE13rZaZ5/PHHi9mxxx5bzLbaaqvOcffaa69i9uIX\nv7iYfe973+scd1njCAwAAFANDQwAAFANDQwAAFANDQwAAFANDQwAAFANDQwAAFANyyiP42/+5m+K\n2RZbbNHzuAcffHAxO+OMM3oed1nymte8pphtu+22xeznP//5dEwHps2GG25YzLqWGl28eHHP+/zq\nV79azN7znvf0PO5s8cQTTxSziX4ub3/724vZ1772tZ7nBDX513/912J26qmn9jxu1/Nr/vz5PY/b\nq0cffbSY7b333p3b5pyL2emnn17MNt98885x77vvvs68No7AAAAA1dDAAAAA1dDAAAAA1dDAAAAA\n1dDAAAAA1dDAAAAA1Zi1yyhvtNFGxexZz3pWMUspdY77hje8oZh95zvfmXhilTjzzDOL2V577VXM\nlluuu2fuGtdSySxL9t1332K2ySabTMs+3/a2t03LuMuSiy++uJj99re/LWZdy2IDja9//evF7Jpr\nrilml1xySee4z3jGM4pZ1yUYrrrqqs5xh+G73/1uMeu61MRxxx3XOe5pp51WzC666KIJ5zXTOAID\nAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUY9Yuo9y1TOnWW29dzHLOnePWtFTyxhtv\n3Jl3LfP6d3/3d8Ws63t03XXXde7z8MMP78xhWfHa1752Wsad6DlGt67lkNdaa60BzgSWPY8++mgx\nu/baa4vZHXfc0Tlu1/N2zpw5E0+sz1796lcXs+c85zmd2+6+++7FrOvvq4mWyX/qU59azCyjDAAA\nMI00MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDVm7XVgZouNNtqomL3lLW/p3PYT\nn/hEv6cTr3rVqzrzW265pe/7hNlk/vz5w55C1bpq1DbbbDPAmcDs8uCDDxazyy67rHPbXq+r1XVt\nlIiIl7/85cXs+OOPL2brrLNOMVtuue5jB//5n/9ZzO6///5i9vSnP71z3AsuuKAzr40jMAAAQDU0\nMAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDVm7TLKv/3tb4vZpZdeWsxe8pKXdI57yCGHFLMz\nzjijmN17773FbIUVun9MXcsAnnvuucVs66237hy3yxNPPFHMPv/5zxczyyQzWxxwwAGd+U477dTT\nuD/96U8789NPP72ncWnssMMOxWyi5U+7pJR63hZmu66/2Sbymte8ppi99KUv7dy2qx50+dznPlfM\nuv4WjIj43e9+V8zuvPPOYtb192dExI033tiZ18YRGAAAoBoaGAAAoBoaGAAAoBoaGAAAoBoaGAAA\noBoaGAAAoBqzdhnlrmWLb7/99p7HPeGEE4rZu9/97mL2/e9/v5itscYanft8xzveUcy6lu7MOXeO\n26VrqeT3vOc9PY8Ls8XixYt72m4qz1siDj/88M78wAMPLGa9/swiIj71qU/1vC3MBiuuuGIx6/qb\nLaL7b50jjjiimD300EOd437hC18oZl3P6VtvvbVz3Olw8sknD3yfw+QIDAAAUA0NDAAAUA0NDAAA\nUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUI1Zex2YLgcffHAxe+Yzn9m57Qte8IJituWWW/aUTcVy\ny5V71Klc0+BnP/tZz9sCTKd58+YVsze96U2Dm8goN9xww1D2CzNJ17VeDjnkkGJ2zDHHdI7bdX2s\nX/3qV8Vszz337Bx3GNdzYXIcgQEAAKqhgQEAAKqhgQEAAKqhgQEAAKqhgQEAAKqhgQEAAKphGeVx\n3H///cXsFa94Ree2X/jCF4pZ1zJ/c+fOLWarrrpq5z5vu+22Yta1PPM222zTOS4w85x66qnDnsKM\n0LVU8rnnnlvMnv3sZ/e8z0WLFhWzD3/4w53b/uEPf+h5v1CTTTfdtJgdeeSRxeztb3/7dEwnrrji\nimJmmeR6OQIDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUwzLKS+mBBx7ozPfdd9+e\nxl1jjTWK2UorrdS57b333lvM3ve+9xWz+fPnTzwxYEZ5xzve0ZmfccYZA5rJcL3tbW8rZlNZKrnL\nMcccU8xOOumkadknzDSvfvWrO/MTTzyxmG222WbF7Morryxmu+22W+c+r7vuumL2whe+sHNb6uQI\nDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA3LKM8QDz300LSMu9Zaa/W87Q033FDM\n/t//+389jwtELLdcb68f7bLLLp151/LCX/7yl3va53TZfPPNO/Nzzz23mG255Zb9nk5ERNx0003F\n7Oyzz56WfcJM84pXvKKYdS2THBHxzGc+s5gdeOCBxezMM88sZo8++mjnPnPOxWzllVfu3JY6OQID\nAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUw3VglnFHHnlkMetaNz0i4t57\n7y1mt912W89zgtng/PPP78yvuuqqYrbNNtv0vN8PfvCDxezCCy/sedwuW221VTH70Ic+VMw23HDD\nznG32GKLYrZ48eKJJzaOe+65pzPffffdi9n111/f0z5hJjrggAOK2VFHHVXMNtlkk85xjz322GJ2\n2mmnTTCr8e25556d+XrrrVfMTjnllJ72yczmCAwAAFANDQwAAFANDQwAAFANDQwAAFANDQwAAFAN\nDQwAAFANyygv45ZbrtyjTrQM6WGHHdbv6cCscccdd3TmDzzwwLTst2tJ49/97nfFrNdliaeiqz5F\n9D6nE044oZh95Stf6dzWUsnMFl1LnG+88cbF7Nvf/nbnuEcffXRP85kzZ04x61oePqL7shDnnXde\nT/NhZnMEBgAAqIYGBgAAqIYGBgAAqIYGBgAAqIYGBgAAqIYGBgAAqIZllJcB2267bTHrWoa0a9nB\niIhddtmlmL397W8vZgcffHDnuEDEfvvtV8z22WefYvbWt761c9znPe95Pc9pplm0aFEx+/nPf17M\n5s+fX8zuvPPOKc0JZrtLL720M3/00UeL2dy5c4vZoYceWsy23377zn1ecsklxey6667r3JY6OQID\nAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUQwMDAABUI010LZBJDZLSLyJiu6lPh/Gs\nvPLKnfn//J//s5jtu+++xWwqP/vDDjusmH3605/uedzZIuechj2HZclsqkEbbrhhZ/7KV76ymO2w\nww7F7MADD+x5Tr3qunZDRMRnPvOZYnbOOef0ezqzihrUXzXWoJNOOqmYvfvd7y5mCxcu7By36zow\nK664YjFbc801i9lEtWKPPfYoZvfff3/ntgzHVGuQIzAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAA\nAEA1NDAAAEA1LKNcgY033rgzv/nmm4tZSuVV6h555JHOcT/+8Y8Xs29+85vF7LbbbuscF0uY9psa\nBEtHDeqvGmtQ15LGRxxxRDF7wxve0Dnu1ltvXcwuvvjiYnb22WcXs6985Sud+7zvvvs6c2YeyygD\nAACzhgYGAACohgYGAACohgYGAACohgYGAACohgYGAACohmWUK7DGGmt05t/+9reLWdcyyvPnz+8c\n9wc/+EH3xOiZJUz7Sw2CpaMG9ZcaBEvHMsoAAMCsoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEB\nAACqscKwJ8DEHnrooc785S9/+YBmAgAAw+UIDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0N\nDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUA0NDAAAUI1+NTDz+jQOQC/m\nDXsCwKw2b9gTgNlkhT6N82B7u6BP48Gyal4seb7QP2oQTM68UIOmgxoEkzMv+lCDUs556lMBAAAY\nAO+BAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGB\nAQAAqqGBAQAAqqGBAQAAqqFGSDUzAAAciklEQVSBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAA\nqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGBAQAAqqGB\nAQAAqqGBAQAAqqGBqUxK6aiUUk4pnTbsuQxaSmn39mv/9bDnArOVGqQGwTCpQWpQxJAamJTSKiml\ng1JK30op3ZxSejil9FhK6Y6U0gUppU+klLYZxtyWNSml09pf9l4+5g1wnnu3RWn7Qe2zFyml56WU\nTk8p3dr+zt6VUjo/pfS6Yc+NyVODBkcN6r+U0moppcNSSpemlO5NKS1KKS1IKX0vpfQPw54fE1OD\nBkcNml4ppS+N+n59b1D7XWFQOxqRUtojIr4YERuO+vSiiHgkIp4SEbu0Hx9NKf0oIt6cc75n0PNc\nhjwQEXeO8/lVI2LN9t/j5RERT0zLjMa3d0S8MSIejohLBrjfSUspHRQRn4slz5s/RsQ6EbFbROyW\nUvpCzvm/DWt+TI4aNHBqUB+llJ4fEd+OiE3aTz0eEY9GxKbtx44R8dnhzI7JUIMGTg2aJimll0bE\ngcPY90CPwKSU3hFN4d0wIq6P5oveKOe8as553YhYKSL+OiKOjIjbI+KVEfH0Qc5xWZNzfk/OecOx\nHxHxnlGPeVLefvx+iFOfUdon6eejaV6+GREbt7+za0bEeyPizxFxcErpH4c3SyaiBg2eGtQ/KaXN\nI+L/RNO8XBAR20fEKjnntaOpRbtG84cxM5QaNHhq0PRIKa0Yzd9Fj0fEVYPe/8COwKSUtovm1evl\nIuI7EbFvznnR6MfknJ+IiCsj4sqU0r9F8wT+06DmCB0+Fs3v7rURsV/7uxo550cj4oSU0tMi4rCI\nOCql9L9yzg8Pb6qMRw1iGXBqNEd9vx8Rrx2pQxEROeeHIuIn7QczkBrEMuZDEfFXEfGJ9nbbQe58\nkEdgjo7mlYVbIuItY5+0Y+WcH885H5lz/s3oz6eUdm7Ps1vQ3n91SukH7XsRFqeU3jvm8RuklP49\npXRdSmlhSumBlNJlKaUPpJRWHm/fKaWftvs4oDS/9nzjnFLaeczn/+LNZSmlt6WUfp5Seiil9GBK\n6Scppb/t+tpTSlumlM5ov6ZH27l/vDTf6ZZSuqL9mvZKKa2XUjo+pfTbdm63tY9ZfdQ5kOsVxnlu\nmz886nO7p5RyNIdNIyLmjzn/tNgIpJR2Tc37T+5rf7a/aE/z6quU0pyI2Km9e/LoPxpGOb69XTci\nXtPvOdAXapAaVGUNave1Q0S8LCIWR8S7C3WImU0NUoOqrUFj9rtZRHw0Im6OiGOne3/jGcgRmJTS\nxhHx6vbuCf16dTql9IGIOC4icjTnOC4ek78oIn4QzR+VEREPRVM8Xth+7J9SemXO+a5+zGec+X0p\nIt4RzTmUj0RziH/niHhZSmnvnPO3xtnmZe2c57SfejAinhERR0XzXoufTsdcJ+lpEfHLaA5nL4rm\ntKmpWhTNuadrR8TK0fyMFo7KHxlvo5TSuyPi5Pbug9Gcy7pdRHwxpbRpzvmj42xzXER8ICIeyTmv\nvhRzfGpErNj++/rxHpBzviOl9EBErBURfxsRZy7F+EwzNUgN6lBDDYqIeHN7e0nO+Zal3JYhU4PU\noA611KDR/kdErBIR/5hzfjSlNIWhejOoIzA7jfr3eX0ac4OI+NdoDsc+Nee8TkSsHhFnRUSklNaJ\n5jzTdSPiPyLiRTnnNdvHvCmaN2A/LyK+1qf5jLVnNP/h/PeIWDPnvFZEPDMiLorm+35SSukvGsh2\nzt+M5kl7ZURs2263ekS8rZ3vu6dpvpNxdEQ8FhEvj4g5Oec1oilEPcs5/7g9F3Vk5Yp/GXP+6Wbj\nbLZJRJwQTdFevz3/e240p1dERByeUnrGVOY1dpqj/r18x+NGsuf0cd/0hxqkBo2rkhoUEfGS9vaX\nKaW5KaUT05LVEG9PKX2j/WOVmUkNUoPGVVENioiIlNLfR/NC7Xdyzv36XV5qg2pgnt3eLoqI3/Zp\nzFUi4hs553/IOd8ZEZFzXpRzvq3ND4nmlfP7I+KVOefL28c8kXM+KyL2bR/3ipTSrn2a02hrR8Q7\nc86fzzkvbPd9c0TsF80bnp4azRswRzskItaPiHsjYrec89Xtdn/KOZ8eEQdH8wr/sKzQzuuCnHNu\n53bjEOaxRjSncn0otyuz5Jzvi4h3RcTvomkkXt/H/f1nLDkH+a/Ge0BKaZNoCmxE87NlZlGDQg3q\no0HXoIiILdrbFaN5Bfgfo/kDdmE0P8s3RcSlKaX/3uf90h9qUKhBfTSMGjTSYB4fTd05tN/jL41B\nNTAjhy7vH/mBj5VS+khq1j8f+3FCx7jzO7K92tsv5ZzvGBvmnH8UEZe2d/ee6Avowa0R8b/H2e/t\nEXFZe/e5Y+KROZ+Sx18y8WvRnDs7LGfnnH83xP2PyBHxqSd9MufFEfHd9u7Y723knD+Yc05Le9g0\nN2/U/1l799DCObj/NOrfayzN+AyEGrRkv2rQ1A20BrWvUq/W3n1XNEvtvjMi1mhfdd8imtXJRl7V\nfuHSjM9AqEFL9qsGTd1Aa9Aon4rmhZNP5Jxv7XGMvhjKhSwL1ojmmzL2o9RpPxoRV48XpJRWiiU/\nuK4VWS5ob7db2slOwhWlIhURf2hv1xn5RDvnkVOPLhxvo3a8i/o2w6V36cQPGYjfj7zaNI4nfW/7\n5OhoCsYzIuJ7KaXtUkorppSellL6ZDSHyEeO0iwuDcKMpgapQZM16Bq03Jh/H5VzPjXn/HjEf70C\n/PqIuDuaV14P6+O+GRw1SA2arIH/HZSaC2weFBHXRcS/93PsXgyqgbmvvV07Fd7pk3M+vO0KU845\nxcTnZN7bdprjWTeWfG1/KDwmImLkMOtTJthXLx7qyEZWHllx1OfWjSXvobi9Y9uur2e63T3EfY+2\ntN/bKcs5/ySaNeMXR8QrIuIX0RwCvy0iPhxNURt5pen+fu6bvlCD/pIaNDUDrUFtozL6BZKTxnnM\nQxFxSnv35f3aN32jBv0lNWhqBlqDUnPNly9ERIqIf8g5D31p70E1MNe2t6vEkvN4p2qyS0iu0qf9\nMdgr0s44OeeTornA2Jci4tfRHB6/NCLeH82b+EYOyfbr/Gb6Rw1aNszmGjTyB91tI+8nGMfIKonr\npmb5d2YONWjZMFtr0H+L5ojeORFxWbtk9H99xJLGc/lRn5/WHmNQDczoQ4GDuEbGfbHkNJ5NOh43\ncnXbsR31yLJ4XU/6fr+J7L5Y8sTYqONxXdkwjV5KsPR9G+Yb7/oi53xVzvmgnPPWOedNc87b55w/\n3b4aMXIIfqYcYmYJNWhiatDM9uulfHzp1B2GQw2amBo0c23a3r4+mqM/Yz9e1+avGvW56Tgt8b8M\npIHJOf8+mjW9IyLe03Zr07m/x2NJsd+l46Ejq25cOebzI6cAPT3GkVLaPJrVNfqmnfPIxapeVthv\nKmXDlpsLcj3W3h33+xbNmvMlI4V28IuJ90FK6cXRvD8mR8QZQ54OY6hBE1ODZnwN+nF7+/SU0mqF\nx2zV3t7VLj7CDKEGTUwNmvE1aEYZ5Jv4PxrNewY2jYivppSm+5DmWe3tASmlJy1rm1J6ZSxZV/8b\nY+L/aG9fWxj78KlPb1zfbG8PSimtO06+b0TMm6Z998PI923PsUH7H+4/dmz7YHvb14I4CCmlVSPi\nxPbuWUNaUpGJqUETU4Nmbg36RjR/HC0X43wdKaU1olmZLCLi+wOcF5OnBk1MDZqBNWjU6mXjfkTE\nyAVJzxv1+Sumc04Da2ByzldGc/GhxdH8YK9KKR04+kmVGpullA6L5mqrU3FyNNfvWDUizk8pvaDd\nx/IppTdGxNfbx/0453zBmG3PiuaV9K1TSieklNZut10/pXRiROwff3mV1H75bETcFRHrRcQPU0rb\ntPtdMaX0lmjeoPnANOy3X0YK4KEppb9vVxSJlNK2EfHD6F4RY+RVl91TStPxZsJIKR2XUsoppaW+\nAnJKaZWU0qdTSi8ZObe8/V3aJZpTA14UzTnqXcWJIVKDJkUNmqE1qF169vj27sfb392Rr2/ziDg7\nmjdiPxrjLK/K8KlBk6IGzdAaNOPknAf6ERF7RPOEyqM+Ho3m/MtFYz7//YjYcsz2O7fZgkns60XR\nnFM5Mt6D7b5G7l8dzRVMx9v2+DFz+WM0RefPEXFARCxoP7/zmO2Oaj9/Wse8Tmsfc9Q42U7RFIWR\n/d4/6vtySUQcO9H4k/w5HDCyj0k89or2sXtN8LhV2+/pyNwfb7/nOSLujGZ99xwRD4+z7dNGPfbP\n0TQDCyLiN6Mes3ub/7pjDoe0j/neONlxpf1P4nuw+ji/D38adf+GiNhi0M8nH0v/oQapQTXWoHb7\n5aN5pXPk63tszO/XwojYc9jPMR8T/hzVIDWoyhrUsc+zSvucro+BXwcm5/zdiHhmNBfjOieaCxIt\njog1o3lyXBgRx0TEc3LOf5dzvr401iT2dVk0V07/dDR/YK4YzS/FFdGsk//inPNdhc0/EM0rJVfH\nkifODyNi15zzab3OaRJzvjAinh8RZ0ZTzFaO5hf4qGjOVX2stO2w5eac650j4jPRrNAV0TwZT4nm\nzVzXdWz7h2i+vnOjKbbrR3OYfdPpm/FSWRTNcsk/jmYJxznRvAp0cTTLK2+dc7b6WAXUoAnnrAbN\nzBoUubmC+hsj4q3R/J4+Es0FLhdE8zU+L+f8neHNkMlQgyacsxo0Q2vQTJLazgkAAGDGG/gRGAAA\ngF5pYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGpoYAAAgGqs\n0I9BUko3R8SaEbGgH+PBMmxeRDyYc37GsCeyLFGDYNLmhRrUd2oQTNq86EMNSjnnKc8kpXRvRKw7\n5YFglsg5p2HPYVmiBsHSUYP6Sw2CpTPVGtSvU8gW9GkcgF4sGPYEgFltwbAnALOJ98AAAADV0MAA\nAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV\n0MAAAADVWGHYEwBg+F71qlcVs/POO69z27322quYnXPOOT3PCQDG4wgMAABQDQ0MAABQDQ0MAABQ\nDQ0MAABQDQ0MAABQDQ0MAABQDcsoAxBHHHFEMcs5d2774Q9/uJhZRhmAfnMEBgAAqIYGBgAAqIYG\nBgAAqIYGBgAAqIYGBgAAqIYGBgAAqIZllAFmiXe9613F7KUvfWkxm2gZ5Z/97Gc9zwkAlpYjMAAA\nQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDUsowxA51LJEy2jfMwxx/R7OgBQ5AgMAABQ\nDQ0MAABQDQ0MAABQDQ0MAABQDQ0MAABQDQ0MAABQDQ0MAABQDdeBWQZst912xex973tfMZs3b17n\nuDvuuGMx+8Y3vlHMjj322GJ21VVXde4TmJpNN920mH3iE58oZgsXLixmb33rWzv3ec8990w8MWBW\nWG211YrZL3/5y2L2sY99rJh9/etfn9KcWPY4AgMAAFRDAwMAAFRDAwMAAFRDAwMAAFRDAwMAAFRD\nAwMAAFTDMsozxNprr13Mjj/++M5t3/SmNxWzOXPm9DynnHMx22uvvYrZy172smL2N3/zN537vOWW\nWyaeGFD0zne+s5jNnTu3mHUtb3rOOedMaU7A7PHJT36ymG222WbF7I477piO6QzFtttuW8xcTqI/\nHIEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACqYRnlAdpmm22K2Wc/+9litv3220/H\ndKbN+uuvX8w22GCDzm0towxT81d/9VfFLKVUzPbff//pmA4wy+y66649bffnP/+5zzOZXgcddFAx\nO+mkk4rZP//zP3eOe+yxx/Y8p9nEERgAAKAaGhgAAKAaGhgAAKAaGhgAAKAaGhgAAKAaGhgAAKAa\nGhgAAKAargPTZ8stV+4JjzjiiGK2ww47FLOcc+c+Fy5cWMy+/e1vF7ONNtqoc9xddtmlMwcGb6ut\nturMX/e61xWzs88+u5hdd911Pc8JmD2e+tSnduYbbrhhMbvjjjuK2eWXX97znIZhn332KWYrrrhi\nMVt11VWnYzqzjiMwAABANTQwAABANTQwAABANTQwAABANTQwAABANTQwAABANSyj3GfrrLNOMdt7\n7717GvP666/vzP/+7/++mD3/+c8vZscee2xP8wGG5ytf+UpnnlIqZpZKBqZq55137sznzp1bzA45\n5JBi9thjj/U6pWnzvOc9r5i98IUvHOBMGMsRGAAAoBoaGAAAoBoaGAAAoBoaGAAAoBoaGAAAoBoa\nGAAAoBqWUe6zefPmFbOu5U27sq222qpzn1deeeWE8+pF15y6XHjhhcXssssu63U6wCTcfffdxeyU\nU04Z4Exmpqc85Smdec65mN1zzz39ng5U5wMf+EDP215++eV9nMn0e//731/MVl999Z7GPP/883ud\nDqM4AgMAAFRDAwMAAFRDAwMAAFRDAwMAAFRDAwMAAFRDAwMAAFTDMsp99pvf/Kan7DnPeU4x61rW\nc1i65nTccccNcCaw7Nl0002L2SabbNK57a233tpTNgxdX2dExHrrrVfMXve61xWzN7zhDcXs2c9+\nduc+u2rbxz72sWL2yU9+snNcWFastdZanfltt91WzK699tp+T2dKJrpMRVct6dUDDzzQ9zFnI0dg\nAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAamhgAACAargOTJ8tWrSomH3qU58qZl/5\nyld63ufjjz9ezBYvXlzMVllllZ732bXO+6WXXtrzuED39U/mzp3bue1nPvOZfk9n2lx22WWdedfX\nmlIqZl3Xcpnoulpd+eGHH17MvvWtb3WOe91113XmsKy44YYbitkjjzwywJlM7CMf+UhnPmfOnJ7G\nve+++4rZH//4x57G5C85AgMAAFRDAwMAAFRDAwMAAFRDAwMAAFRDAwMAAFRDAwMAAFTDMsoD9LWv\nfa2Y/fa3v+153K7lkE877bRitummm/a8z/PPP7+YdS0fCEysa4ngriwi4t577+33dCa02mqrFbOu\npZKf8pSndI7btaTxRN+Hkuuvv74z33LLLYtZ19fZ63KrUJuf/vSnnflOO+00mIlM0jOf+cxi9qY3\nvalz25tuuqmncW+//faeMibPERgAAKAaGhgAAKAaGhgAAKAaGhgAAKAaGhgAAKAaGhgAAKAallGe\nIbqWGp3Iu971rmI2laWSuxxxxBHTMu4uu+xSzJ72tKcVs8svv7xz3ImWToWZpGv54K5sWLrqV9ey\nxBN9Lb1+rWeffXYx+853vtO5bdfS8/fcc09PGSxLzjrrrM58n332KWabb755Mbvxxht7ntOOO+5Y\nzM4444xituKKK3aO2/W1fuhDH5p4YkwbR2AAAIBqaGAAAIBqaGAAAIBqaGAAAIBqaGAAAIBqaGAA\nAIBqaGAAAIBquA5MBbrWTY+ImD9/fjFLKfW836OPPrqY3XfffT2P2+Wwww4rZq9+9auL2aGHHto5\nruvAUJNf/OIXxeyXv/xl57YvfelLi9kXv/jFYva+972vmB133HGd++yqM13Xclm4cGHnuOecc05P\n2bXXXlvMrrnmms59ds33a1/7WjG79dZbO8eFZcUPf/jDzvz//t//W8x22223YtZ1HZidd965c58X\nXHBBMeuqT+eff37nuF/+8peLWdffHX/4wx86x2XqHIEBAACqoYEBAACqoYEBAACqoYEBAACqoYEB\nAACqoYEBAACqYRnlCrz5zW/uzFdfffVi1rUk6D333NM57sc+9rHuiU2Dz3/+88Xs/vvvL2Z33HHH\ndEwHqrPjjjv2lB1++OHFrKuOTKRr2eKJakzXUsmvf/3ri9nll19ezCb6Ws4+++xidswxx3RuC0Ts\nt99+xeyKK64oZv/2b/9WzFZaaaXOfXY9r88777xi9sEPfrBz3A022KCYrbLKKsXMsurTzxEYAACg\nGhoYAACgGhoYAACgGhoYAACgGhoYAACgGhoYAACgGpZRniE233zzYjbRMn9dnnjiiWJ24IEH9jzu\ndDn33HN7ymC2mGj58xe84AXF7MILLyxmKaViNtHSwz/60Y+K2f7771/MVltttc5xP/GJTxSzj3zk\nI8Wsa76///3vO/d55JFHFrOJvvdA9yUPdthhh2J20kknFbOnPOUpnfu8+OKLi9mXv/zlYnbjjTd2\njtu1VPLjjz9ezG655ZbOcZk6R2AAAIBqaGAAAIBqaGAAAIBqaGAAAIBqaGAAAIBqaGAAAIBqWEZ5\ngFZeeeVi1rV84Jw5c3re589+9rNidt555/U8LjAcXcsSR0TceeedxWyi5ZB73W699dYrZj/4wQ+K\n2SabbNI57ty5c3ua0zXXXFPMdtlll859WioZpk9Xfdp7770HOJPJWXXVVYvZ8ssvP8CZMJYjMAAA\nQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDVcB2aADjvssGK22267FbOJrsFw\n++23F7M3vvGNE08MqMZE1yn50pe+VMze+c53FrOUUs9z+uu//uti1lW/Jtrn3XffXcxOPPHEYvbJ\nT36yc1yAyVhppZWKmevADJcjMAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDUso9xn\nz33uc4vZv/zLvxSzqSxh+uMf/7iY3X///T2PC9SnawnhuXPnFrPXv/71xWyipdy7dG17zjnndG77\n/ve/v5jdeuutPc8JYDLuuuuuYrZw4cIBzoSxHIEBAACqoYEBAACqoYEBAACqoYEBAACqoYEBAACq\noYEBAACqYRnlPlt99dWLWa9Lkd58882d+T/90z/1NG5t1l577WK2yiqrdG57xx139Hs6MCN1LS+8\n1157DXAmAHVbf/31i9mcOXMGOBPGcgQGAACohgYGAACohgYGAACohgYGAACohgYGAACohgYGAACo\nhgYGAACohuvA9NmvfvWrYnbRRRcVsxe84AXF7JBDDunc51133TXxxCqx5pprFrPvfve7xezMM8/s\nHPfkk0/ueU4AAMwcjsAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADV0MAAAADVsIxyny1cuLCY\n7bLLLsVsyy23LGbXX3/9lOZUkz322KOY7bDDDsVsomWUAQCWxuLFi4tZznmAM2EsR2AAAIBqaGAA\nAIBqaGAAAIBqaGAAAIBqaGAAAIBqaGAAAIBqWEZ5hphNSyV3WbBgwbCnAAAQF198cTH7+c9/PsCZ\nMJYjMAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDU0MAAAQDVSznnqg6T0i4jYburTgdkh55yG\nPYdliRoES0cN6i81CJbOVGuQIzAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAA\nAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1NDAAAEA1+tXAzOvTOAC9mDfsCQCz2rxh\nTwBmkxX6NM6D7e2CPo0Hy6p5seT5Qv+oQTA580INmg5qEEzOvOhDDUo556lPBQAAYAC8BwYAAKiG\nBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYA\nAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKiGBgYAAKjG/wcXSvXOKpf3zQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 408,
              "height": 265
            }
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzAAAAISCAYAAAATGyqSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 408,
              "height": 265
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BquXIOINj86F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0df619cf-2457-4ae3-b7e5-c2819970d3b2"
      },
      "source": [
        "for epoch in range(1, 10 + 1):\n",
        "    train(10, model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(),\"mnist_cnn.pt\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.291340\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.226841\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.139306\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.003811\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.745064\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.428748\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.053957\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.768116\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.844016\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.506139\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.425677\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.448089\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.613346\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.324516\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.648004\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.295262\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.522862\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.453673\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.468865\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.379229\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.544355\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.265195\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.283021\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.265806\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.169134\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.238505\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.184544\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.479239\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.374871\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.247288\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.169500\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.126702\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.356550\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.291464\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.260531\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.115008\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.229302\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.182131\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.089306\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.130391\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.372186\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.176290\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.131120\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.074582\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.147632\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.138257\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.280475\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.198790\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.124487\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.171264\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.193153\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.171184\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.107211\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.282039\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.241914\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.209600\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.282035\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.149989\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.074656\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.055143\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.059660\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.155541\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.080427\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.200901\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.084129\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.132972\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.104126\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.182183\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.101560\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.170237\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.183661\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.147873\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.145677\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.222400\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.175044\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140929\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.294558\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.169934\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.078865\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.206246\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.110784\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.110578\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.186935\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.171269\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.178877\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.072767\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.115809\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.073322\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.116528\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.140405\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.069019\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.325752\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.073442\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.073565\n",
            "\n",
            "Test set: Average loss: 0.1080, Accuracy: 9652/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.149228\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.063493\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.077485\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.105429\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.041469\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.067353\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.024496\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.070810\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.114136\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.105884\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.051179\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.080450\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.035166\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.076352\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.082329\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.094063\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.091415\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.116740\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.110856\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.194037\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.076902\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.064903\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.167884\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.052441\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.145067\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.038354\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.120435\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.078668\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.024224\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.092936\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.091646\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.070316\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.037171\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.197595\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.099245\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.045479\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.122142\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.143910\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.112205\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.174414\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.156496\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.011616\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.135518\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.102016\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.036178\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.061721\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.073843\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.062878\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.038718\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.067662\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.030953\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.065273\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.090562\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.219158\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.054439\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.019595\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.029380\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.076283\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.054486\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.030815\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.039810\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.029221\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.078176\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.039025\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.081662\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.016778\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.064587\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.017106\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.033439\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.073929\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.075837\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.053193\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.129400\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.033032\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.086652\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.071660\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.166121\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.162868\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.017853\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.071306\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.059766\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.056257\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.014750\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.148697\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.086210\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.082188\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.015547\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.078091\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.073280\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.130846\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.043913\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.035927\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.037071\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.056827\n",
            "\n",
            "Test set: Average loss: 0.0579, Accuracy: 9819/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.071822\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.030804\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.096807\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.032585\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.053561\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.121084\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.130691\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.093699\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.055204\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.070897\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.058812\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.057951\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.106606\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.031500\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.021769\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.073739\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.093513\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.032881\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.149130\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.181349\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.032018\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.026480\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.043843\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.356667\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.077173\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.070714\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.013096\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.079340\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.063760\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.093698\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.145395\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.094540\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.175785\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.026495\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.024245\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.009791\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.045576\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.065570\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.190931\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.014404\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.026028\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.091696\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.099398\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.111776\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.045034\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.011581\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.058107\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.023408\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.085037\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.030130\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.013546\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.026750\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.032074\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.052351\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.007110\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.014305\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.021606\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.134084\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.029732\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.058800\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.031457\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.009416\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.022552\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.063462\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.068167\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.069803\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.032548\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.020959\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.072444\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.059720\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.099898\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.062989\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.092307\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.089077\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.023172\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.008925\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.036411\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.028049\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.037022\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.009104\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.054284\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.009606\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.032469\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.016345\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.064878\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.098147\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.013171\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.066242\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.057302\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.045939\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.023325\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.019197\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.157481\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.080943\n",
            "\n",
            "Test set: Average loss: 0.0490, Accuracy: 9841/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.021456\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.042747\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.054231\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.021090\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.051045\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.089617\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.025656\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.060370\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.105577\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.068942\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.063383\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.044366\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.080247\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.015055\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.017045\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.025588\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.024032\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.092785\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.058071\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.034681\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.016081\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.047921\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.018378\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.031766\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.050419\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.013617\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.012320\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.252879\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.025357\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.074987\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.029571\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.028869\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.038791\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.060376\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.064580\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.015902\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.151098\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.022861\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.019906\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.015919\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.025324\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.038654\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.041753\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.022481\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.032837\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.006185\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.034210\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.058761\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.043285\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.012511\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.017415\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.050110\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.033845\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.067745\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.019282\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.023121\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.020673\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.062230\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.049244\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.014093\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.024983\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.110453\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.052883\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.007042\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.056163\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.013978\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.005629\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.013944\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.058370\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.052353\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.084918\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.048104\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.035107\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.132662\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.066123\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.141856\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.021141\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.016821\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.075643\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.050149\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.008720\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.018697\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.016162\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.032529\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.023854\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.040442\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.019244\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.024781\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.006762\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.032784\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.069146\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.054592\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.052295\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.050231\n",
            "\n",
            "Test set: Average loss: 0.0380, Accuracy: 9886/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.017328\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.047849\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.020157\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.011552\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.013578\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.009621\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.023553\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.088306\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.113948\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.040554\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.086546\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.051705\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.009856\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.121690\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.009898\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.018794\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.030958\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.039816\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.021450\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.084410\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.067309\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.019394\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.021507\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.014397\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.029067\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.013306\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.073984\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.027761\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.066910\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.030035\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.026001\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.093956\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.009833\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.100917\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.035371\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.015259\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.177579\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.010501\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.003744\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.031976\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.041644\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.011322\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.012889\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.035355\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.050782\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.036268\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.065278\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.040355\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.013512\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.073044\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.029841\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.043589\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.077051\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.068318\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.084779\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.068538\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.030520\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.024645\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.015753\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.128371\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.007075\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.046241\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.010272\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.194506\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.009864\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.026504\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.019636\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.031189\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.005967\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.068720\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.010182\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.034773\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.031013\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.065043\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.016476\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.007998\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.034350\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.013514\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.028331\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.033708\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.008010\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.029621\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.093673\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.002993\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.032166\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.012342\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.006919\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.047094\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.068629\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.105351\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.008119\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.048614\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.012490\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.070770\n",
            "\n",
            "Test set: Average loss: 0.0468, Accuracy: 9849/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.090940\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.032191\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.084932\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.011356\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.006350\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.024453\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.018231\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.018525\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.002395\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.047827\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.028493\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.014469\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.046955\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.040382\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.006868\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.065942\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.008548\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.007009\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.006341\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.009495\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.021861\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.014957\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.072844\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.017499\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.034528\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.033212\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.002634\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.025776\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.003696\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.107738\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.009099\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.029242\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.127952\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.036502\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.017166\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.012467\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.010344\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.051829\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.013097\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.014198\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.035695\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.015551\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.085113\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.088710\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.046750\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.001273\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.028170\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.202644\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.001843\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.018776\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.005339\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.036846\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.030069\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.020464\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.013489\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.018276\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.062256\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.056378\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.047274\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.034142\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.014722\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.017933\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.008180\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.022983\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.002796\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.008874\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.005050\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.216055\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.023050\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.005713\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.003427\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.012526\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.002479\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.006697\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.010694\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.044642\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.005072\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.018266\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.064131\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.004116\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.035611\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.028090\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.082528\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.003846\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.060051\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.075246\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.099393\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.140297\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.021941\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.054612\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.009147\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.011229\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.014780\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.044725\n",
            "\n",
            "Test set: Average loss: 0.0328, Accuracy: 9891/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.022577\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.015529\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.095240\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.020877\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.015652\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.022739\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.061809\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.061245\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.003333\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.025590\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.009026\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.134822\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.214002\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.010279\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.130584\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.007656\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.018461\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.059145\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.003445\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.033236\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.049287\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.014070\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.015482\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.040603\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.011483\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.030559\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.008829\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.056954\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.010286\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.002479\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.006281\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.046289\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.046630\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.067337\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.016958\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.009436\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.009472\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.043925\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.088061\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.029427\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.035701\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.074060\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.045812\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.031506\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.015142\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.019777\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.019219\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.010061\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.007062\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.018914\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.029507\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.029036\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.061519\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.006635\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.078206\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.041409\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.041301\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.005354\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.001540\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.021559\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.004986\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.015898\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.001724\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.023788\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.035154\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.008812\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.021580\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.010690\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.016033\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.010343\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.006203\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.010368\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.026464\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.083208\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.008919\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.003137\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.020494\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.002455\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.007834\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.014856\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.033968\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.017445\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.031938\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.015330\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.081662\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.004113\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.044807\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.005586\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.023516\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.012270\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.018243\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.025695\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.018251\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.022861\n",
            "\n",
            "Test set: Average loss: 0.0329, Accuracy: 9898/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.018943\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.013020\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.045774\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.001791\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.040794\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.034657\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.015861\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.003172\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.009689\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.019906\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.004693\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.004856\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.024817\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.011801\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.028122\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.001402\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.038300\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.003178\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.031837\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.002643\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.004990\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.011047\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.006712\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.011219\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.108349\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.033895\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.064130\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.012398\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.003127\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.020854\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.031117\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.013950\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.057338\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.001094\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.018561\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.010377\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.062802\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.058347\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.010262\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.003752\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.024851\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.037374\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.005978\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.007893\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.020314\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.004877\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.003733\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.014543\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.011980\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.003062\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.004755\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.008424\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.055586\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.007952\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.009656\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.013220\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.059092\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.048098\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.077130\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.004904\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.051819\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.005710\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.022431\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.003222\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.039398\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.027620\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.033682\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.005148\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.036025\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.020295\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.011814\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.009208\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.014920\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.009105\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.017796\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.025587\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.026119\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.000813\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.049870\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.009559\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.013192\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.028343\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.024201\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.001876\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.028289\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.042638\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.085525\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.025571\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.047399\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.003163\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.016187\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.098175\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.050276\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.014250\n",
            "\n",
            "Test set: Average loss: 0.0290, Accuracy: 9901/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.025928\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.004094\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.011474\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.022877\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.003529\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.011333\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.007565\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.015272\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.020790\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.024473\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.002926\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.111671\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.012769\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.047580\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.010607\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.020261\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.003471\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.115271\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.003918\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.004586\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.003870\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.030571\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.008245\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.006320\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.003414\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.003523\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.003668\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.040419\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.133603\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.003087\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.004555\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.006027\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.027535\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.034659\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.034850\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.001888\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.006232\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.014509\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.029780\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.001562\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.009003\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.026189\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.013483\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.022094\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.075201\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.004148\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.004295\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.013263\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.001433\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.087221\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.014475\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.019828\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.020968\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.003399\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.006110\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.008881\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.023771\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.000602\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.028517\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.051240\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.003987\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.002455\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.057104\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.047737\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.001240\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.010264\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.014764\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.005544\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.007557\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.004975\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.008332\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.031551\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.020383\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.002973\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.010784\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.035383\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.026388\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.015662\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.022873\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.001104\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.004464\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.013578\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.018189\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.001259\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.009906\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.000759\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.032426\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.002019\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.028081\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.008188\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.044471\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.102271\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.000839\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.040124\n",
            "\n",
            "Test set: Average loss: 0.0316, Accuracy: 9893/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.014892\n",
            "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.009075\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.017780\n",
            "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.001377\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.015032\n",
            "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.022744\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.000529\n",
            "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.007105\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.086431\n",
            "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.112713\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.032685\n",
            "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.095836\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.023081\n",
            "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.049433\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.001024\n",
            "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.009267\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.004037\n",
            "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.003410\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.008860\n",
            "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.008562\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.036957\n",
            "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.018111\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.002406\n",
            "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.035824\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.003844\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.011958\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.023355\n",
            "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.005240\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.012443\n",
            "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.004944\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.010332\n",
            "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.086460\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.066019\n",
            "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.017376\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.005114\n",
            "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.012478\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.006763\n",
            "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.007632\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.022018\n",
            "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.019434\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.027394\n",
            "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.012587\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.004354\n",
            "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.010908\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.040370\n",
            "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.005540\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.008459\n",
            "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.031357\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.000695\n",
            "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.007931\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.015521\n",
            "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.037735\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.002638\n",
            "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.056843\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.016766\n",
            "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.004962\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.006648\n",
            "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.004979\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.003701\n",
            "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.008648\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.082451\n",
            "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.018617\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.013263\n",
            "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.007794\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.006955\n",
            "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.118700\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.018292\n",
            "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.003849\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.009605\n",
            "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.030721\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.028998\n",
            "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.009298\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.028290\n",
            "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.005942\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.018732\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.001469\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.014247\n",
            "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.014772\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.002166\n",
            "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.001395\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.118364\n",
            "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.001694\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.010171\n",
            "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.027192\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.002288\n",
            "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.019691\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.004241\n",
            "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.042383\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.002303\n",
            "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.037286\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.008626\n",
            "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.012897\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.008398\n",
            "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.007169\n",
            "\n",
            "Test set: Average loss: 0.0287, Accuracy: 9907/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8zd3JgNrh_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}